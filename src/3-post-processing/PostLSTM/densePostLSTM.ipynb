{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM post-processing RF"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, random_split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30438 30438.0 30438.0 30438.0\n",
      "30674 30674.0 30674.0 30674.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('/mnt/guanabana/raid/home/slomp006')\n",
    "\n",
    "# Reference data (inputs containing band sequence (of 92), targets containing respective lcf sequence (of 4))\n",
    "dense_train_inputs_df = pd.read_csv('Input/Dense/dense_train_input.csv')\n",
    "dense_train_targets_df = pd.read_csv('Input/Dense/dense_train_targets.csv')\n",
    "dense_vali_inputs_df = pd.read_csv('Input/Dense/dense_vali_input.csv')\n",
    "dense_vali_targets_df = pd.read_csv('Input/Dense/dense_vali_targets.csv')\n",
    "\n",
    "# Predictions\n",
    "dense_RF_pred = pd.read_csv('Output/RF/DenseRFPredict.csv')\n",
    "dense_LSTM_pred = pd.read_csv('Output/LSTM/LSTM_dense.csv')\n",
    "\n",
    "# Dense RF pred does not contain a correct amount of rows (one or more samples does not have the proper length = 92)\n",
    "grouped = dense_RF_pred.groupby('location_id')\n",
    "dense_RF_pred = grouped.filter(lambda x: len(x) == 92)\n",
    "\n",
    "# LSTM pred does not have a date column, make one first\n",
    "dense_LSTM_pred['date'] = dense_LSTM_pred.groupby('location_id').cumcount() + 1\n",
    "\n",
    "# Now also create validation set and use similar IDs\n",
    "common_ids = set(dense_vali_inputs_df['location_id']).intersection(dense_RF_pred['location_id'])\n",
    "common_ids_LSTM = set(dense_vali_inputs_df['location_id']).intersection(dense_LSTM_pred['location_id'])\n",
    "\n",
    "dense_RF_pred = dense_RF_pred[dense_RF_pred['location_id'].isin(common_ids)]\n",
    "dense_LSTM_pred = dense_LSTM_pred[dense_LSTM_pred['location_id'].isin(common_ids_LSTM)]\n",
    "\n",
    "dense_vali_inputs_LSTM_df = dense_vali_inputs_df[dense_vali_inputs_df['location_id'].isin(common_ids_LSTM)]\n",
    "dense_vali_targets_LSTM_df = dense_vali_targets_df[dense_vali_targets_df['location_id'].isin(common_ids_LSTM)]\n",
    "dense_vali_inputs_df = dense_vali_inputs_df[dense_vali_inputs_df['location_id'].isin(common_ids)]\n",
    "dense_vali_targets_df = dense_vali_targets_df[dense_vali_targets_df['location_id'].isin(common_ids)]\n",
    "                                                                          \n",
    "# Order by ID, then by date / year \n",
    "dense_RF_pred = dense_RF_pred.sort_values(by=['location_id', 'date'])\n",
    "dense_vali_inputs_df = dense_vali_inputs_df.sort_values(by=['location_id', 'date'])\n",
    "dense_vali_targets_df = dense_vali_targets_df.sort_values(by=['location_id', 'reference_year']) \n",
    "\n",
    "dense_LSTM_pred = dense_LSTM_pred.sort_values(by=['location_id', 'date'])\n",
    "dense_vali_inputs_LSTM_df = dense_vali_inputs_LSTM_df.sort_values(by=['location_id', 'date'])\n",
    "dense_vali_targets_LSTM_df = dense_vali_targets_LSTM_df.sort_values(by=['location_id', 'reference_year']) \n",
    "\n",
    "# When respectively divided by 4 and 92, aggregated and dense should have same length\n",
    "print(len(common_ids), len(dense_RF_pred)/92, len(dense_vali_inputs_df)/92, len(dense_vali_targets_df)/4)\n",
    "print(len(common_ids_LSTM), len(dense_LSTM_pred)/92, len(dense_vali_inputs_LSTM_df)/92, len(dense_vali_targets_LSTM_df)/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We now have 8 data frames, 2 for training:\n",
      "Training inputs: (3085680, 13) with targets: (134160, 17) \n",
      "\n",
      "2 for validation for RF and 1 for RF prediction:\n",
      "Validation inputs: (2800296, 12) with targets: (121752, 15)\n",
      "and predictions: (2800296, 14) \n",
      "\n",
      "And 2 for validation for LSTM and 1 for LSTM prediction:\n",
      "Validation inputs: (2822008, 12) with targets: (122696, 15)\n",
      "and predictions: (2822008, 15) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"We now have 8 data frames, 2 for training:\")\n",
    "print(\"Training inputs:\", dense_train_inputs_df.shape, \"with targets:\", dense_train_targets_df.shape, \"\\n\")\n",
    "      \n",
    "print(\"2 for validation for RF and 1 for RF prediction:\")\n",
    "print(\"Validation inputs:\", dense_vali_inputs_df.shape, \"with targets:\", dense_vali_targets_df.shape)\n",
    "print(\"and predictions:\", dense_RF_pred.shape, \"\\n\")\n",
    "\n",
    "print(\"And 2 for validation for LSTM and 1 for LSTM prediction:\")\n",
    "print(\"Validation inputs:\", dense_vali_inputs_LSTM_df.shape, \"with targets:\", dense_vali_targets_LSTM_df.shape)\n",
    "print(\"and predictions:\", dense_LSTM_pred.shape, \"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create tensors from input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF dense predictions contained NaN values: tensor(True)\n",
      "Validation band sequence contained NaN values: tensor(False) \n",
      "\n",
      "RF dense predictions has shape: torch.Size([28507, 92, 7])\n",
      "Vali band input sequence has shape: torch.Size([28507, 92, 9])\n",
      "Vali lcf sequence has shape: torch.Size([28507, 4, 7])\n",
      "Corresponding dense IDs has shape torch.Size([28507, 92, 4]) and aggregated IDs: torch.Size([28507, 4, 5]) \n",
      "\n",
      "LSTM dense predictions contained NaN values: tensor(False)\n",
      "Validation band sequence contained NaN values: tensor(False) \n",
      "\n",
      "RF dense predictions has shape: torch.Size([30674, 92, 7])\n",
      "Vali band input sequence has shape: torch.Size([30674, 92, 9])\n",
      "Vali lcf sequence has shape: torch.Size([30674, 4, 7])\n",
      "Corresponding dense IDs has shape torch.Size([30674, 92, 4]) and aggregated IDs: torch.Size([30674, 4, 5]) \n",
      "\n",
      "Train band sequence contained NaN values: tensor(False) \n",
      "\n",
      "Train input sequence has shape: torch.Size([33540, 92, 9])\n",
      "Train lcf sequence has shape: torch.Size([33540, 4, 7])\n"
     ]
    }
   ],
   "source": [
    "# Classes are targets\n",
    "targets = ['bare', 'crops',\n",
    "       'grassland', 'shrub', 'tree', 'urban_built_up', 'water']\n",
    "\n",
    "# Original input variables (now raw band values are input)\n",
    "inputs = ['x', 'y', 'b1', 'b2', 'b3', 'b4',\n",
    "         'b5', 'b6', 'b7']\n",
    "\n",
    "# Also save IDs for later\n",
    "IDs_aggregated = ['sample_id', 'location_id', 'reference_year', 'x', 'y']\n",
    "IDs_dense = ['location_id', 'date', 'x', 'y']\n",
    "\n",
    "# Create predictions list\n",
    "RF_pred_list = []\n",
    "LSTM_pred_list = []\n",
    "\n",
    "# Validation list\n",
    "vali_target_list = []\n",
    "LSTM_vali_target_list = []\n",
    "\n",
    "# Training\n",
    "train_target_list = []\n",
    "\n",
    "for colname in targets: \n",
    "    # Get column of feature\n",
    "    col_RF = dense_RF_pred[colname]\n",
    "    col_LSTM = dense_LSTM_pred[colname]\n",
    "    col_training = dense_train_targets_df[colname]\n",
    "    col_vali = dense_vali_targets_df[colname]\n",
    "    col_vali_LSTM = dense_vali_targets_LSTM_df[colname]\n",
    "\n",
    "    # Create tensors with sequence lengths of 92 for prediction, and 4 for training and vali (reference is aggregated)\n",
    "    RF_tensor = torch.tensor(col_RF.values).view(-1, 92, 1).to(dtype=torch.float32)\n",
    "    LSTM_tensor = torch.tensor(col_LSTM.values).view(-1, 92, 1).to(dtype=torch.float32)\n",
    "    training_tensor = torch.tensor(col_training.values).view(-1, 4, 1).to(dtype=torch.float32)\n",
    "    vali_tensor = torch.tensor(col_vali.values).view(-1, 4, 1).to(dtype=torch.float32)\n",
    "    LSTM_vali_tensor = torch.tensor(col_vali_LSTM.values).view(-1, 4, 1).to(dtype=torch.float32)\n",
    "\n",
    "    # Append to lists\n",
    "    RF_pred_list.append(RF_tensor)\n",
    "    LSTM_pred_list.append(LSTM_tensor)\n",
    "    train_target_list.append(training_tensor)\n",
    "    vali_target_list.append(vali_tensor)\n",
    "    LSTM_vali_target_list.append(LSTM_vali_tensor)\n",
    "    \n",
    "# We now each class as a separate tensor but we want them as one. So concatenate the tensors along the last dimension\n",
    "tensor_RF_preds = torch.cat(RF_pred_list, dim=-1)\n",
    "tensor_LSTM_preds = torch.cat(LSTM_pred_list, dim=-1)\n",
    "tensor_train_targets = torch.cat(train_target_list, dim=-1)\n",
    "tensor_vali_targets = torch.cat(vali_target_list, dim=-1)\n",
    "LSTM_tensor_vali_targets = torch.cat(LSTM_vali_target_list, dim=-1)\n",
    "\n",
    "# Do the same for the input variables\n",
    "train_input_list = []\n",
    "vali_input_list = []\n",
    "LSTM_vali_input_list = []\n",
    "\n",
    "for colname in inputs:\n",
    "    col_train = dense_train_inputs_df[colname]\n",
    "    col_vali = dense_vali_inputs_df[colname]\n",
    "    col_vali_LSTM = dense_vali_inputs_LSTM_df[colname]\n",
    "    \n",
    "    # Band sequence is sequence of 92\n",
    "    train_tensor = torch.tensor(col_train.values).view(-1, 92, 1).to(dtype=torch.float32)\n",
    "    vali_tensor = torch.tensor(col_vali.values).view(-1, 92, 1).to(dtype=torch.float32)\n",
    "    LSTM_vali_tensor = torch.tensor(col_vali_LSTM.values).view(-1, 92, 1).to(dtype=torch.float32)\n",
    "    \n",
    "    train_input_list.append(train_tensor)\n",
    "    vali_input_list.append(vali_tensor)\n",
    "    LSTM_vali_input_list.append(LSTM_vali_tensor)\n",
    "\n",
    "tensor_train_inputs = torch.cat(train_input_list, dim=-1)\n",
    "tensor_vali_inputs = torch.cat(vali_input_list, dim=-1)\n",
    "LSTM_tensor_vali_inputs = torch.cat(LSTM_vali_input_list, dim=-1)\n",
    "\n",
    "# And for IDs (if no NaN values, not necessary)\n",
    "Agg_ID_list = []\n",
    "Dense_ID_list = []\n",
    "LSTM_Agg_ID_list = []\n",
    "LSTM_Dense_ID_list = []\n",
    "\n",
    "# IDs for aggregated output\n",
    "for colname in IDs_aggregated:\n",
    "    ID_col = dense_vali_targets_df[colname]\n",
    "    LSTM_ID_col = dense_vali_targets_LSTM_df[colname]\n",
    "    ID_tensor = torch.tensor(ID_col.values).view(-1, 4, 1).to(dtype=torch.float32)\n",
    "    LSTM_ID_tensor = torch.tensor(LSTM_ID_col.values).view(-1, 4, 1).to(dtype=torch.float32)\n",
    "    Agg_ID_list.append(ID_tensor)\n",
    "    LSTM_Agg_ID_list.append(LSTM_ID_tensor)\n",
    "\n",
    "# IDs for dense output\n",
    "for colname in IDs_dense:\n",
    "    if colname == \"date\":\n",
    "        ID_col = dense_RF_pred[colname].str.replace(\"-\", \"\").astype(int) # make 2015-01-07 to 20150107 int value\n",
    "#         ID_col = dense_RF_pred[colname]\n",
    "        LSTM_ID_col = dense_LSTM_pred[colname]\n",
    "    else:\n",
    "        ID_col = dense_RF_pred[colname]\n",
    "        LSTM_ID_col = dense_LSTM_pred[colname]\n",
    "        \n",
    "    ID_tensor = torch.tensor(ID_col.values).view(-1, 92, 1).to(dtype=torch.float32)\n",
    "    LSTM_ID_tensor = torch.tensor(LSTM_ID_col.values).view(-1, 92, 1).to(dtype=torch.float32)\n",
    "    Dense_ID_list.append(ID_tensor)\n",
    "    LSTM_Dense_ID_list.append(LSTM_ID_tensor)\n",
    "       \n",
    "tensor_Agg_IDs = torch.cat(Agg_ID_list, dim=-1)\n",
    "tensor_Dense_IDs = torch.cat(Dense_ID_list, dim=-1)\n",
    "LSTM_tensor_Agg_IDs = torch.cat(LSTM_Agg_ID_list, dim=-1)\n",
    "LSTM_tensor_Dense_IDs = torch.cat(LSTM_Dense_ID_list, dim=-1)\n",
    "\n",
    "# Check for NaN \n",
    "tensor_RF_preds_old = tensor_RF_preds\n",
    "tensor_LSTM_preds_old = tensor_LSTM_preds\n",
    "tensor_train_inputs_old = tensor_train_inputs\n",
    "tensor_vali_inputs_old = tensor_vali_inputs\n",
    "LSTM_tensor_vali_inputs_old = LSTM_tensor_vali_inputs\n",
    "\n",
    "# create an empty mask\n",
    "mask = None\n",
    "\n",
    "# Remove for each tensor that need to be similar\n",
    "if torch.isnan(tensor_RF_preds).any():\n",
    "    mask = torch.isnan(tensor_RF_preds).any(dim=1).any(dim=1)\n",
    "    tensor_RF_preds = tensor_RF_preds[~mask]\n",
    "    tensor_vali_inputs = tensor_vali_inputs[~mask]\n",
    "    tensor_vali_targets = tensor_vali_targets[~mask]\n",
    "    tensor_Agg_IDs = tensor_Agg_IDs[~mask]\n",
    "    tensor_Dense_IDs = tensor_Dense_IDs[~mask]\n",
    "\n",
    "if torch.isnan(tensor_LSTM_preds).any():\n",
    "    mask = torch.isnan(tensor_LSTM_preds).any(dim=1).any(dim=1)\n",
    "    tensor_LSTM_preds = tensor_LSTM_preds[~mask]\n",
    "    LSTM_tensor_vali_inputs = LSTM_tensor_vali_inputs[~mask]\n",
    "    LSTM_tensor_vali_targets = LSTM_tensor_vali_targets[~mask]\n",
    "    LSTM_tensor_Agg_IDs = LSTM_tensor_Agg_IDs[~mask]\n",
    "    LSTM_tensor_Dense_IDs = LSTM_tensor_Dense_IDs[~mask]\n",
    "    \n",
    "if torch.isnan(tensor_vali_inputs).any():\n",
    "    mask = torch.isnan(tensor_vali_inputs).any(dim=1).any(dim=1)\n",
    "    tensor_RF_preds = tensor_RF_preds[~mask]\n",
    "    tensor_vali_inputs = tensor_vali_inputs[~mask]\n",
    "    tensor_vali_targets = tensor_vali_targets[~mask]\n",
    "    tensor_Agg_IDs = tensor_Agg_IDs[~mask]\n",
    "    tensor_Dense_IDs = tensor_Dense_IDs[~mask]\n",
    "    \n",
    "if torch.isnan(tensor_train_inputs).any():\n",
    "    mask = torch.isnan(tensor_train_inputs).any(dim=1).any(dim=1)\n",
    "    tensor_train_inputs = tensor_train_inputs[~mask]\n",
    "    tensor_train_targets = tensor_train_targets[~mask]\n",
    "       \n",
    "# Check final tensors (including shape)\n",
    "print(\"RF dense predictions contained NaN values:\", torch.isnan(tensor_RF_preds_old).any())\n",
    "print(\"Validation band sequence contained NaN values:\", torch.isnan(tensor_vali_inputs_old).any(), \"\\n\")\n",
    "print(\"RF dense predictions has shape:\", tensor_RF_preds.shape)\n",
    "print(\"Vali band input sequence has shape:\", tensor_vali_inputs.shape)\n",
    "print(\"Vali lcf sequence has shape:\", tensor_vali_targets.shape)\n",
    "print(\"Corresponding dense IDs has shape\", tensor_Dense_IDs.shape, \"and aggregated IDs:\", tensor_Agg_IDs.shape, \"\\n\")\n",
    "\n",
    "print(\"LSTM dense predictions contained NaN values:\", torch.isnan(tensor_LSTM_preds_old).any())\n",
    "print(\"Validation band sequence contained NaN values:\", torch.isnan(LSTM_tensor_vali_inputs_old).any(), \"\\n\")\n",
    "print(\"RF dense predictions has shape:\", tensor_LSTM_preds.shape)\n",
    "print(\"Vali band input sequence has shape:\", LSTM_tensor_vali_inputs.shape)\n",
    "print(\"Vali lcf sequence has shape:\", LSTM_tensor_vali_targets.shape)\n",
    "print(\"Corresponding dense IDs has shape\", LSTM_tensor_Dense_IDs.shape, \"and aggregated IDs:\", LSTM_tensor_Agg_IDs.shape, \"\\n\")\n",
    "\n",
    "print(\"Train band sequence contained NaN values:\", torch.isnan(tensor_train_inputs_old).any(), \"\\n\")\n",
    "print(\"Train input sequence has shape:\", tensor_train_inputs.shape)\n",
    "print(\"Train lcf sequence has shape:\", tensor_train_targets.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create synthetic training data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upsample and normalise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([33540, 92, 10]) torch.Size([33540, 4, 7])\n"
     ]
    }
   ],
   "source": [
    "# First upsample some urban cases as was done before\n",
    "# Function to upsample classes where value is > 0 (thus every sample where class is represented)\n",
    "def upsample(X, Y, i, n):\n",
    "    idx = Y[:, -1, i] != 0 # -1 to account for one that is already in the data set\n",
    "    X_sub = X[idx].repeat(n-1, 1, 1)\n",
    "    Y_sub = Y[idx].repeat(n-1, 1, 1)\n",
    "    return X_sub, Y_sub\n",
    "\n",
    "# Function to only upsample classes where value = 100 (thus every sample where class is 100)\n",
    "def upsample100(X, Y, i, n):\n",
    "    idx = Y[:, -1, i] == 100\n",
    "    X_sub = X[idx].repeat(n-1, 1, 1)\n",
    "    Y_sub = Y[idx].repeat(n-1, 1, 1)\n",
    "    return X_sub, Y_sub\n",
    "\n",
    "urban_X, urban_Y = upsample(tensor_train_inputs, tensor_train_targets, 5, 5) # repeat indice 5 (urban) times 5 where it is represented\n",
    "urban_100_X, urban_100_Y = upsample100(tensor_train_inputs, tensor_train_targets, 5, 100) # repeat indice 5 (urban) times 100 where it is represented with 100\n",
    "\n",
    "# Create upsampled training data (and keep Y information)\n",
    "X_train = torch.cat([tensor_train_inputs, urban_X, urban_100_X], dim=0)\n",
    "Y_train = torch.cat([tensor_train_targets, urban_Y, urban_100_Y], dim=0)\n",
    "Y_coord = X_train[:, :, 1].unsqueeze(2) # Y coordinate is indice 1 (X = 0)\n",
    "\n",
    "# Overwrite with normal training data (and keep Y information)\n",
    "X_train = torch.cat([tensor_train_inputs], dim=0)\n",
    "Y_train = torch.cat([tensor_train_targets], dim=0)\n",
    "Y_coord = X_train[:, :, 1].unsqueeze(2) # Y coordinate is indice 1 (X = 0)\n",
    "\n",
    "# Normalise\n",
    "X_mean = X_train.mean(dim=0)\n",
    "X_std = X_train.std(dim=0)\n",
    "\n",
    "# Standardize the training set\n",
    "X_train = (X_train - X_mean) / X_std\n",
    "\n",
    "# Add unnormalized Y coordinate to X tensor\n",
    "X_train = torch.cat([Y_coord, X_train], dim=-1)\n",
    "\n",
    "# Create the TensorDataset for the training set\n",
    "train_dataset = TensorDataset(X_train, Y_train)\n",
    "\n",
    "print(X_train.shape, Y_train.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple LSTM model to generate synthetic noise data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "\n",
    "# Model\n",
    "class SynthModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=1, dropout=0):\n",
    "        super().__init__()\n",
    "        # LSTM \n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        \n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # Activation\n",
    "        self.activation = nn.Tanh()\n",
    "        \n",
    "        # Linear with Xavier Uniform\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "        init.xavier_uniform_(self.linear.weight)\n",
    "        \n",
    "        # Softmax\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Put input through LSTM layer\n",
    "        x, _ = self.lstm(x)\n",
    "        \n",
    "        # Put LSTM output through dropout layer\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Apply tanh activation function\n",
    "        x = self.activation(x)\n",
    "        \n",
    "        # Linear transform x to shape [batch size, sequence length = 92, output size = 7]\n",
    "        x = self.linear(x)\n",
    "        \n",
    "        # Make sure output distribution sums to 100\n",
    "        x = self.softmax(x) * 100\n",
    "       \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch: 4/5, Best loss: 13.534 (obtained at epoch 3)\n",
      " Done. Result at epoch 4 is taken.\n"
     ]
    }
   ],
   "source": [
    "# Input size is number of input variables and output size is number of classes\n",
    "synthmodel = SynthModel(input_size=len(inputs), hidden_size=128, output_size=len(targets)) \n",
    "\n",
    "# Define the loss function and optimizer\n",
    "loss_fn = nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(synthmodel.parameters(), lr=0.01, weight_decay=0.0)\n",
    "\n",
    "# Create a DataLoader for the training set and validation sets (specify batch size)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=1028, shuffle=True) \n",
    "\n",
    "# Retain data of best loss\n",
    "best_loss = float(\"inf\")\n",
    "best_epoch = 0\n",
    "\n",
    "# Epochs\n",
    "num_epochs = 10 # The higher, the less noise\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    # Progress\n",
    "    print(\"\\rAt epoch: {}/{}, Best loss: {} (obtained at epoch {})\".format(epoch, \n",
    "                                                                            num_epochs, \n",
    "                                                                            round(best_loss, 3),\n",
    "                                                                            best_epoch), end='\\r')\n",
    "    \n",
    "    # Store epoch results in list\n",
    "    epoch_pred = []\n",
    "    epoch_pred_tensor = []\n",
    "    epoch_actual = []\n",
    "    epoch_actual_tensor = []\n",
    "    epoch_loss = []\n",
    "    \n",
    "    # Retain input tensor for later\n",
    "    input_tensor = []\n",
    "    \n",
    "    # Loop over the training set\n",
    "    for X, Y in train_loader:\n",
    "\n",
    "        input_tensor.append(X)\n",
    "        \n",
    "        # Clear the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        Y_pred = synthmodel(X[:, :, 1:]) # Don't use unnormalised Y coord\n",
    "        Y = Y.repeat_interleave(repeats=23, dim=1)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = loss_fn(Y_pred, Y)\n",
    "        epoch_loss.append(loss)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Predictions per batch\n",
    "        Y_pred_list = [x.tolist() for x in Y_pred]\n",
    "        Y_list = [x.tolist() for x in Y]\n",
    "        \n",
    "        # Add batch prediction to list\n",
    "        epoch_pred.append(Y_pred_list)\n",
    "        epoch_actual.append(Y_list)\n",
    "        epoch_pred_tensor.append(Y_pred)\n",
    "        epoch_actual_tensor.append(Y)\n",
    "        \n",
    "    # Retain a tensor format for the Markov Chain    \n",
    "    epoch_pred_tensor = torch.cat(epoch_pred_tensor, dim=0)\n",
    "    epoch_actual_tensor = torch.cat(epoch_actual_tensor, dim=0)\n",
    "    \n",
    "    # Also retain input tensor\n",
    "    input_tensor = torch.cat(input_tensor, dim=0)\n",
    "    \n",
    "    avg_loss = sum(epoch_loss)/len(epoch_loss)\n",
    "    \n",
    "    # Retain prediction if best loss\n",
    "    if avg_loss < best_loss:\n",
    "        best_loss = avg_loss.item()\n",
    "        best_pred = epoch_pred\n",
    "        best_actual = epoch_actual\n",
    "        best_epoch = epoch\n",
    "        best_pred_tensor = epoch_pred_tensor\n",
    "        best_actual_tensor = epoch_actual_tensor\n",
    "        best_input_tensor = input_tensor[:, :, 1:]\n",
    "        best_Y_coord = input_tensor[:, :, 0].unsqueeze(2)\n",
    "        \n",
    "print(\"\\n\", \"Done.\", \"Result at epoch\", best_epoch, \"is taken.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save tensors to file for later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(best_pred_tensor.detach(), 'LSTM(RF)/Synth/pred_tensor.pt')\n",
    "# torch.save(best_actual_tensor.detach(), 'LSTM(RF)/Synth/actual_tensor.pt')\n",
    "# torch.save(best_input_tensor.detach(), 'LSTM(RF)/Synth/input_tensor.pt')\n",
    "# torch.save(best_Y_coord.detach(), 'LSTM(RF)/Synth/Y_coord_tensor.pt')\n",
    "\n",
    "# # Use torch.load(path) to retrieve them "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check synthesized (noise) data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from statistics import mean\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# # Make lists of predictions and actual fractions (reference)\n",
    "nested_pred = best_pred # results from the epoch with the minimum loss is taken\n",
    "nested_actual = best_actual\n",
    "\n",
    "unnested_pred = []\n",
    "for data in nested_pred:\n",
    "  for batch in data:\n",
    "    for timestep in batch:\n",
    "      for target in range(len(timestep)):\n",
    "        unnested_pred.append(timestep[target])\n",
    "\n",
    "unnested_actual = []\n",
    "for data in nested_actual:\n",
    "  for batch in data:\n",
    "    for timestep in batch:\n",
    "      for target in range(len(timestep)):\n",
    "        unnested_actual.append(timestep[target])\n",
    "\n",
    "# These lists contain output for entire predictions \n",
    "# Now retain lists for each class\n",
    "pred_class = {}\n",
    "true_class = {}\n",
    "\n",
    "# Initialize lists for each class in predictions\n",
    "for i in range(len(targets)):\n",
    "  pred_class[f'{targets[i]}'] = unnested_pred[i::len(targets)]\n",
    "\n",
    "# Initialize lists for each class in reference data\n",
    "for i in range(len(targets)):\n",
    "  true_class[f'{targets[i]}'] = unnested_actual[i::len(targets)]\n",
    "\n",
    "RMSEavg = 0\n",
    "MAEavg = 0\n",
    "\n",
    "# Plot the lists as graphs\n",
    "\n",
    "# Loop through the data and plot the actual and predicted values\n",
    "for i in range(len(targets)):\n",
    "    # Get the data for the current class\n",
    "    true = true_class[f'{targets[i]}']\n",
    "    predicted = pred_class[f'{targets[i]}']\n",
    "\n",
    "    # Define the x-axis data as a range of values from 0 to the length of the data\n",
    "    x = range(len(true))\n",
    "\n",
    "    # Create a new figure\n",
    "    fig = plt.figure(i)\n",
    "\n",
    "    # Create a figure with certain size\n",
    "    fig = plt.figure(figsize=(20, 3))\n",
    "\n",
    "    # Create axes\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "    # Plot the actual and predicted values\n",
    "    ax.plot(x, true, label='Actual')\n",
    "    ax.plot(x, predicted, label='Synthesized')\n",
    "\n",
    "    # Add a legend\n",
    "    ax.legend()\n",
    "\n",
    "    # Set the title using the class name\n",
    "    var_name = f'{targets[i]}'\n",
    "    ax.set_title(var_name)\n",
    "\n",
    "    # Show the figure\n",
    "    plt.show()\n",
    "\n",
    "    # Print RMSE / MAE\n",
    "    rmse = mean_squared_error(predicted, true) ** 0.5\n",
    "    RMSEavg = RMSEavg + rmse\n",
    "    print(f'RMSE for {var_name}: {round(rmse, 2)}')\n",
    "\n",
    "    difference = [abs(predicted - true) for predicted, true in zip(predicted, true)]\n",
    "    mae = mean(difference)\n",
    "    MAEavg = MAEavg + mae\n",
    "    print(f'MAE for {var_name}: {round(mae, 2)}')\n",
    "\n",
    "print(\"\\n\")\n",
    "RMSEavg = RMSEavg / len(targets)\n",
    "MAEavg = MAEavg / len(targets)\n",
    "\n",
    "print(f'Average RMSE is {round(RMSEavg, 2)} and average MAE is {round(MAEavg, 2)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have three train X: using actual lcf: torch.Size([33540, 92, 17]) using synth data: torch.Size([33540, 92, 17])\n",
      "and both: torch.Size([67080, 92, 17]) \n",
      "\n",
      "x2, as we have a normalised one and a non normalised one \n",
      "\n",
      "We have three respective train Y: torch.Size([33540, 4, 7]) torch.Size([33540, 4, 7]) and torch.Size([67080, 4, 7])\n"
     ]
    }
   ],
   "source": [
    "# Tensors\n",
    "synth_lcf = best_pred_tensor.detach()\n",
    "actual_lcf = best_actual_tensor.detach()\n",
    "input_vars = best_input_tensor.detach()\n",
    "Y_coord_training = best_Y_coord.detach()\n",
    "\n",
    "# Training X (inputted into the model)\n",
    "inputs_plus_actual = torch.cat([Y_coord_training, input_vars, actual_lcf], dim=-1)\n",
    "inputs_plus_synth = torch.cat([Y_coord_training, input_vars, synth_lcf], dim=-1)\n",
    "training_X = torch.cat([inputs_plus_actual, inputs_plus_synth], dim=0)\n",
    "\n",
    "print(\"We have three train X: using actual lcf:\", inputs_plus_actual.shape, \"using synth data:\", inputs_plus_synth.shape)\n",
    "print(\"and both:\", training_X.shape, \"\\n\")\n",
    "\n",
    "# Training X only inputs are normalised, also make one with normalised lcf\n",
    "inputs_plus_actual_norm = torch.cat([input_vars, actual_lcf], dim=-1)\n",
    "inputs_plus_synth_norm = torch.cat([input_vars, synth_lcf], dim=-1)\n",
    "\n",
    "X_mean_all = training_X[:, :, 1:].mean(dim=0)\n",
    "X_std_all = training_X[:, :, 1:].std(dim=0)\n",
    "\n",
    "inputs_plus_actual_norm = (inputs_plus_actual_norm - X_mean_all) / X_std_all\n",
    "inputs_plus_synth_norm = (inputs_plus_synth_norm - X_mean_all) / X_std_all\n",
    "\n",
    "# Now add unnormalised Y coordinate again\n",
    "inputs_plus_actual_norm = torch.cat([Y_coord_training, inputs_plus_actual_norm], dim=-1)\n",
    "inputs_plus_synth_norm = torch.cat([Y_coord_training, inputs_plus_synth_norm], dim=-1)\n",
    "training_X_norm = torch.cat([inputs_plus_actual_norm, inputs_plus_synth_norm], dim=0)\n",
    "\n",
    "print(\"x2, as we have a normalised one and a non normalised one\", \"\\n\")\n",
    "\n",
    "# Training Y (what the model should be trained to predict)\n",
    "actual_lcf1 = actual_lcf[:, 0:22, :].mean(dim=1).unsqueeze(1)\n",
    "actual_lcf2 = actual_lcf[:, 23:55, :].mean(dim=1).unsqueeze(1)\n",
    "actual_lcf3 = actual_lcf[:, 56:78, :].mean(dim=1).unsqueeze(1)\n",
    "actual_lcf4 = actual_lcf[:, 79:91, :].mean(dim=1).unsqueeze(1)\n",
    "actual_lcf_agg = torch.cat([actual_lcf1, actual_lcf2, actual_lcf3, actual_lcf4], dim=1)\n",
    "training_Y = torch.cat([actual_lcf_agg, actual_lcf_agg], dim=0)\n",
    "\n",
    "print(\"We have three respective train Y:\", actual_lcf_agg.shape, actual_lcf_agg.shape, \"and\", training_Y.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regress samples\n",
    "Instead of repeating, perhaps regressed samples are better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regressing sample: 65/67080\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:97: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regressing sample: 67079/67080\n",
      " We now have regressed torch.Size([67080, 4, 7]) into torch.Size([67080, 92, 7])\n"
     ]
    }
   ],
   "source": [
    "def RegressSamples(originalX, originalY):    \n",
    "    \n",
    "    # Clone original tensors\n",
    "    test_Y = originalY.clone().detach()\n",
    "    test_X = originalX.clone().detach()\n",
    "\n",
    "    # Save regressed tensor\n",
    "    regressed_tensor = []\n",
    "\n",
    "    # Loop over samples\n",
    "    for sample in range(test_Y.shape[0]):\n",
    "\n",
    "        # Progress\n",
    "        print(\"\\rRegressing sample: {}/{}\".format(sample, test_Y.shape[0]), end='\\r')\n",
    "\n",
    "        # Create output tensor sample for sample      \n",
    "        out = torch.zeros(1, 92, 7)\n",
    "\n",
    "        # If southern hemisphere, place fractions at first months (important, first indice need to translate to Y coord!!)      \n",
    "        if (test_X[sample, :, 0] < 0).all():\n",
    "\n",
    "            out[:, 0:5, :] = test_Y[sample, 0, :].unsqueeze(0).unsqueeze(1).repeat_interleave(5, dim=1)\n",
    "            out[:, 23:28, :] = test_Y[sample, 1, :].unsqueeze(0).unsqueeze(1).repeat_interleave(5, dim=1)\n",
    "            out[:, 46:51, :] = test_Y[sample, 2, :].unsqueeze(0).unsqueeze(1).repeat_interleave(5, dim=1)\n",
    "            out[:, 69:, :] = test_Y[sample, 3, :].unsqueeze(0).unsqueeze(1).repeat_interleave(23, dim=1)\n",
    "\n",
    "            diff1 = (out[:, 23, :] - out[:, 4, :]).unsqueeze(1)\n",
    "            diff2 = (out[:, 46, :] - out[:, 27, :]).unsqueeze(1)\n",
    "            diff3 = (out[:, 69, :] - out[:, 50, :]).unsqueeze(1)\n",
    "\n",
    "            for diff in range(3):\n",
    "\n",
    "                if diff == 0:\n",
    "                    diff_timesteps = 23-5\n",
    "                    start_timestep = 5-1\n",
    "                    diff_values = diff1\n",
    "                elif diff == 1:\n",
    "                    diff_timesteps = 46-28\n",
    "                    start_timestep = 28-1\n",
    "                    diff_values = diff2\n",
    "                else:\n",
    "                    diff_timesteps = 69-51\n",
    "                    start_timestep = 51-1\n",
    "                    diff_values = diff3\n",
    "\n",
    "                regr_values = []\n",
    "\n",
    "                for i in range(diff_values.shape[2]):\n",
    "\n",
    "                    if diff_values[:, :, i] == 0:\n",
    "                        regr_value = torch.zeros(1, 1).unsqueeze(1)\n",
    "                    else:\n",
    "                        regr_value = torch.tensor(diff_values[:, :, i] / diff_timesteps).unsqueeze(1)\n",
    "\n",
    "                    regr_values.append(regr_value)\n",
    "\n",
    "                regr_values = torch.cat(regr_values, dim=-1)\n",
    "\n",
    "                for next_step in range(diff_timesteps):\n",
    "                    timestep = out[:, start_timestep+next_step, :].unsqueeze(1)\n",
    "                    out[:, start_timestep+next_step+1, :] = timestep + regr_values\n",
    "\n",
    "        # If northern hemisphere, place fractions at the middle months      \n",
    "        else:\n",
    "\n",
    "            out[:, 0:14, :] = test_Y[sample, 0, :].unsqueeze(0).unsqueeze(1).repeat_interleave(14, dim=1)\n",
    "            out[:, 32:37, :] = test_Y[sample, 1, :].unsqueeze(0).unsqueeze(1).repeat_interleave(5, dim=1)\n",
    "            out[:, 55:60, :] = test_Y[sample, 2, :].unsqueeze(0).unsqueeze(1).repeat_interleave(5, dim=1)\n",
    "            out[:, 78:, :] = test_Y[sample, 3, :].unsqueeze(0).unsqueeze(1).repeat_interleave(14, dim=1)\n",
    "\n",
    "            diff1 = (out[:, 32, :] - out[:, 13, :]).unsqueeze(1)\n",
    "            diff2 = (out[:, 55, :] - out[:, 36, :]).unsqueeze(1)\n",
    "            diff3 = (out[:, 78, :] - out[:, 59, :]).unsqueeze(1)\n",
    "\n",
    "            for diff in range(3):\n",
    "\n",
    "                if diff == 0:\n",
    "                    diff_timesteps = 32-14\n",
    "                    start_timestep = 14-1\n",
    "                    diff_values = diff1\n",
    "                elif diff == 1:\n",
    "                    diff_timesteps = 55-37\n",
    "                    start_timestep = 37-1\n",
    "                    diff_values = diff2\n",
    "                else:\n",
    "                    diff_timesteps = 78-60\n",
    "                    start_timestep = 60-1\n",
    "                    diff_values = diff3\n",
    "\n",
    "                regr_values = []\n",
    "\n",
    "                for i in range(diff_values.shape[2]):\n",
    "\n",
    "                    if diff_values[:, :, i] == 0:\n",
    "                        regr_value = torch.zeros(1, 1).unsqueeze(1)\n",
    "                    else:\n",
    "                        regr_value = torch.tensor(diff_values[:, :, i] / diff_timesteps).unsqueeze(1)\n",
    "\n",
    "                    regr_values.append(regr_value)\n",
    "\n",
    "                regr_values = torch.cat(regr_values, dim=-1)\n",
    "\n",
    "                for next_step in range(diff_timesteps):\n",
    "                    timestep = out[:, start_timestep+next_step, :].unsqueeze(1)\n",
    "                    out[:, start_timestep+next_step+1, :] = timestep + regr_values\n",
    "\n",
    "        # Append regressed sample to full regressed tensor list      \n",
    "        regressed_tensor.append(out)\n",
    "\n",
    "    # Concatenate into full shape [num samples, 92, 7]          \n",
    "    regressed_tensor = torch.cat(regressed_tensor, dim=0)\n",
    "\n",
    "    # Return tensor\n",
    "    return regressed_tensor\n",
    "\n",
    "# Perform function on data\n",
    "# Important, indice 0 in argument 1 needs to translate to unnormalised Y coord\n",
    "training_Y_regressed = RegressSamples(training_X, training_Y)\n",
    "training_Y_regressed_actual = training_Y_regressed[:int(training_Y_regressed.shape[0]/2), :, :]\n",
    "training_Y_regressed_synth = training_Y_regressed[int(training_Y_regressed.shape[0]/2):, :, :]\n",
    "\n",
    "print(\"\\n\", \"We now have regressed\", training_Y.shape, \"into\", training_Y_regressed.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check if regressed properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample:\n",
      "tensor([[ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.]]) \n",
      "\n",
      "Regressed sample:\n",
      "tensor([[ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., 88., 12.,  0.,  0.]])\n"
     ]
    }
   ],
   "source": [
    "# Check certain sample\n",
    "i = 4\n",
    "\n",
    "torch.set_printoptions(sci_mode=False, precision=2, linewidth=100)\n",
    "\n",
    "print(\"Original sample:\")\n",
    "print(training_Y[i, :, :].detach(), \"\\n\")\n",
    "print(\"Regressed sample:\")\n",
    "print(training_Y_regressed[i, :, :].detach())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oversample change samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done oversampling change. Changed size 67080 into 132400 \n",
      " ( 6532 change samples into 65320 ) \n",
      "\n",
      "Done oversampling change. Changed size 67080 into 132400 \n",
      " ( 6532 change samples into 65320 ) \n",
      "\n",
      "Done oversampling change. Changed size 67080 into 132400 \n",
      " ( 6532 change samples into 65320 ) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def OversampleChange(originalX, originalY, repeattimes):\n",
    "    \n",
    "    # Create a tensor with all samples that have experienced change\n",
    "    # Make sure X and Y correspond with each other\n",
    "    changed_tensorsY_list = []\n",
    "    changed_tensorsX_list = []\n",
    "\n",
    "    # Loop through samples, break if only one timestep has change\n",
    "    for i in range(originalY.size(0)): \n",
    "        for j in range(originalY.size(1)-1):  \n",
    "            if torch.any(originalY[i, j, :] != originalY[i, j+1, :]):\n",
    "\n",
    "                # Append Y change tensors\n",
    "                change_tensor = originalY[i, :, :].unsqueeze(0)\n",
    "                changed_tensorsY_list.append(change_tensor)\n",
    "\n",
    "                # Append X change tensors\n",
    "                change_tensor_input = originalX[i, :, :].unsqueeze(0)\n",
    "                changed_tensorsX_list.append(change_tensor_input)\n",
    "\n",
    "                break\n",
    "\n",
    "    # Create change tensors            \n",
    "    changed_tensors = torch.cat(changed_tensorsY_list, dim=0)\n",
    "    changed_tensors_input = torch.cat(changed_tensorsX_list, dim=0)\n",
    "    \n",
    "    # Repeat change tensors x amount of times\n",
    "    changed_tensors_repeated = changed_tensors.detach().repeat(repeattimes, 1, 1) \n",
    "    changed_tensors_input_repeated = changed_tensors_input.detach().repeat(repeattimes, 1, 1)\n",
    "    \n",
    "    # Concatenate X and Y back\n",
    "    originalX_oversampled = torch.cat([originalX, changed_tensors_input_repeated], dim=0)\n",
    "    originalY_oversampled = torch.cat([originalY, changed_tensors_repeated], dim=0)\n",
    "    \n",
    "    # Print changed size\n",
    "    print(\"Done oversampling change. Changed size\", originalX.size(0), \"into\", originalX_oversampled.size(0), \"\\n\",\n",
    "         \"(\", changed_tensors.size(0), \"change samples into\", changed_tensors_repeated.size(0), \")\", \"\\n\")\n",
    "    \n",
    "    # Return oversampled X and Y\n",
    "    return originalX_oversampled, originalY_oversampled\n",
    "    \n",
    "# Execute function on data (normalised LCF and non normalised LCF)\n",
    "repeat_number = 10 # Repeating 10 times will give a ~1:1 ratio of change/non-change\n",
    "\n",
    "training_X_oversampled, training_Y_oversampled = OversampleChange(training_X, training_Y, repeat_number)\n",
    "training_X_norm_oversampled, _ = OversampleChange(training_X_norm, training_Y, repeat_number) # Y oversampled discarded as it is the same \n",
    "_, training_Y_regressed_oversampled = OversampleChange(training_X, training_Y_regressed, repeat_number) # X oversampled discarded as its the same\n",
    "\n",
    "# oversampling a regressed sample might take longer (loop over 92 sequence instead of 4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We now have (an unnormalised and normalised) validation RF X: torch.Size([28507, 92, 17]) torch.Size([28507, 92, 17])\n",
      "And a to be predicted validation RF Y: torch.Size([28507, 4, 7]) \n",
      "\n",
      "And (an unnormalised and normalised) validation LSTM X: torch.Size([30674, 92, 17]) torch.Size([30674, 92, 17])\n",
      "And a to be predicted validation LSTM Y: torch.Size([30674, 4, 7]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The way input tensors are set up:\n",
    "tensor_RF_all = torch.cat([tensor_vali_inputs, tensor_RF_preds], dim=-1)\n",
    "tensor_LSTM_all = torch.cat([LSTM_tensor_vali_inputs, tensor_LSTM_preds], dim=-1)\n",
    "# This means that the last 7 columns represent the land cover classes\n",
    "\n",
    "# Split into inputs and land cover fractions\n",
    "RF_X_inputs = tensor_RF_all[:, :, :-len(targets)]\n",
    "RF_X_lcf = tensor_RF_all[:, :, -len(targets):]\n",
    "LSTM_X_inputs = tensor_LSTM_all[:, :, :-len(targets)]\n",
    "LSTM_X_lcf = tensor_LSTM_all[:, :, -len(targets):]\n",
    "\n",
    "# Normalise inputs \n",
    "X_mean_inputs = tensor_train_inputs.mean(dim=0)\n",
    "X_std_inputs = tensor_train_inputs.std(dim=0)\n",
    "RF_X_inputs_normalised = (RF_X_inputs - X_mean_inputs) / X_std_inputs\n",
    "LSTM_X_inputs_normalised = (LSTM_X_inputs - X_mean_inputs) / X_std_inputs\n",
    "\n",
    "# Rejoin data (land cover fractions are thus not normalised)\n",
    "RF_X = torch.cat([RF_X_inputs[:, :, 1].unsqueeze(2), RF_X_inputs_normalised, RF_X_lcf], dim=-1) # indice 1 here represents Y coord\n",
    "LSTM_X = torch.cat([LSTM_X_inputs[:, :, 1].unsqueeze(2), LSTM_X_inputs_normalised, LSTM_X_lcf], dim=-1)\n",
    "\n",
    "# Now do the same, but also normalise land cover fractions (can use x mean and std defined before)\n",
    "RF_X_norm = (RF_X[:, :, 1:] - X_mean_all) / X_std_all\n",
    "RF_X_norm = torch.cat([RF_X_inputs[:, :, 1].unsqueeze(2), RF_X_norm], dim=-1)\n",
    "LSTM_X_norm = (LSTM_X[:, :, 1:] - X_mean_all) / X_std_all\n",
    "LSTM_X_norm = torch.cat([LSTM_X_inputs[:, :, 1].unsqueeze(2), LSTM_X_norm], dim=-1)\n",
    "\n",
    "# And the to be predicted Y\n",
    "RF_Y = tensor_vali_targets\n",
    "LSTM_Y = LSTM_tensor_vali_targets\n",
    "\n",
    "# Print validation data\n",
    "print(\"We now have (an unnormalised and normalised) validation RF X:\", RF_X.shape, RF_X_norm.shape)\n",
    "print(\"And a to be predicted validation RF Y:\", RF_Y.shape, \"\\n\")\n",
    "print(\"And (an unnormalised and normalised) validation LSTM X:\", LSTM_X.shape, LSTM_X_norm.shape)\n",
    "print(\"And a to be predicted validation LSTM Y:\", LSTM_Y.shape, \"\\n\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data sets ready!\n"
     ]
    }
   ],
   "source": [
    "## We now have the following data sets\n",
    "\n",
    "# Input data (Landsat sequence) is always normalised. 'Norm' refers to also normalised input LCF.\n",
    "\n",
    "## Training\n",
    "# Train dataset: using actual+synth\n",
    "train_dataset = TensorDataset(training_X, training_Y)\n",
    "train_dataset_norm = TensorDataset(training_X_norm, training_Y)\n",
    "train_dataset_oversampled = TensorDataset(training_X_oversampled, training_Y_oversampled)\n",
    "train_dataset_norm_oversampled = TensorDataset(training_X_norm_oversampled, training_Y_oversampled)\n",
    "\n",
    "# Regressed data sets\n",
    "train_dataset_regressed = TensorDataset(training_X, training_Y_regressed)\n",
    "train_dataset_norm_regressed = TensorDataset(training_X_norm, training_Y_regressed)\n",
    "train_dataset_regressed_oversampled = TensorDataset(training_X_oversampled, training_Y_regressed_oversampled)\n",
    "train_dataset_norm_regressed_oversampled = TensorDataset(training_X_norm_oversampled, training_Y_regressed_oversampled)\n",
    "\n",
    "# Using only actual/synth (does not include oversampled)\n",
    "train_dataset_actual = TensorDataset(inputs_plus_actual, actual_lcf_agg)\n",
    "train_dataset_synth = TensorDataset(inputs_plus_synth, actual_lcf_agg)\n",
    "train_dataset_norm_actual = TensorDataset(inputs_plus_actual_norm, actual_lcf_agg)\n",
    "train_dataset_norm_synth = TensorDataset(inputs_plus_synth_norm, actual_lcf_agg)\n",
    "train_dataset_regressed_actual = TensorDataset(inputs_plus_actual, training_Y_regressed_actual)\n",
    "train_dataset_regressed_synth = TensorDataset(inputs_plus_synth, training_Y_regressed_actual)\n",
    "train_dataset_regressed_norm_actual = TensorDataset(inputs_plus_actual_norm, training_Y_regressed_actual)\n",
    "train_dataset_regressed_norm_synth = TensorDataset(inputs_plus_synth_norm, training_Y_regressed_synth)\n",
    "\n",
    "# Synth x2 (norm regressed)\n",
    "synth_2x = torch.cat([inputs_plus_synth_norm, inputs_plus_synth_norm], dim=0)\n",
    "lcf_2x = torch.cat([training_Y_regressed_synth, training_Y_regressed_synth], dim=0)\n",
    "train_dataset_regressed_norm_synth_2x = TensorDataset(synth_2x, lcf_2x)\n",
    "\n",
    "## Validation\n",
    "# And of course prediction/validation data set\n",
    "RF_vali_dataset = TensorDataset(RF_X, RF_Y)\n",
    "RF_vali_dataset_norm = TensorDataset(RF_X_norm, RF_Y)\n",
    "LSTM_vali_dataset = TensorDataset(LSTM_X, LSTM_Y)\n",
    "LSTM_vali_dataset_norm = TensorDataset(LSTM_X_norm, LSTM_Y)\n",
    "\n",
    "print(\"Data sets ready!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM post-process model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "\n",
    "# Bidirectional LSTM (nr 3, full sequence input)\n",
    "class BiLSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=1, dropout=0.3):\n",
    "        super().__init__()\n",
    "        \n",
    "        input_size = input_size - 1 # disregard Y coordinate\n",
    "        self.output_size = output_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # LSTM layer\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, bidirectional=True, batch_first=True)\n",
    "        \n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # Activation\n",
    "        self.activation = nn.Tanh()\n",
    "        \n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(hidden_size*2, output_size)\n",
    "        \n",
    "        # Softmax\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        \n",
    "    def forward(self, x_input):\n",
    "        \n",
    "        # Don't use Y coordinate (first indice)\n",
    "        x = x_input[:, :, 1:]\n",
    "        \n",
    "        # Put inputs through LSTM layer \n",
    "        x, _ = self.lstm(x) # [batch size, 4, hidden size]\n",
    "        \n",
    "        # Apply dropout for overfitting\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Tanh activation (non-linearity and zero-centering)\n",
    "        x = self.activation(x)\n",
    "        \n",
    "        # Go through final fully connected layer\n",
    "        x = self.fc(x) # [batch size, 4, 7]\n",
    "        \n",
    "        # Make sure output distribution sums to 100\n",
    "        x = self.softmax(x) * 100\n",
    "        \n",
    "        # Create two outputs: dense and aggregated\n",
    "        # Aggregate based on Y > 0 (northern hemisphere) and Y < 0 (southern hemisphere)\n",
    "        agg_batch = []\n",
    "        for i in range(x_input.shape[0]):\n",
    "            if (x_input[i, :, 0] > 0).all(): # indice 1 is Y coordinate\n",
    "                mean1 = x[i, 9:13,:].unsqueeze(0).mean(dim=1).unsqueeze(1)\n",
    "                mean2 = x[i, 32:36,:].unsqueeze(0).mean(dim=1).unsqueeze(1)\n",
    "                mean3 = x[i, 55:59,:].unsqueeze(0).mean(dim=1).unsqueeze(1)\n",
    "                mean4 = x[i, 78:82,:].unsqueeze(0).mean(dim=1).unsqueeze(1)\n",
    "                agg_sample = torch.cat([mean1, mean2, mean3, mean4], dim=1) # [1, 4, 7]\n",
    "                agg_batch.append(agg_sample)      \n",
    "            else:\n",
    "                mean1 = x[i, 0:4,:].unsqueeze(0).mean(dim=1).unsqueeze(1)\n",
    "                mean2 = x[i, 23:27,:].unsqueeze(0).mean(dim=1).unsqueeze(1)\n",
    "                mean3 = x[i, 46:50,:].unsqueeze(0).mean(dim=1).unsqueeze(1)\n",
    "                mean4 = x[i, 69:73,:].unsqueeze(0).mean(dim=1).unsqueeze(1)\n",
    "                agg_sample = torch.cat([mean1, mean2, mean3, mean4], dim=1) # [1, 4, 7]\n",
    "                agg_batch.append(agg_sample)  \n",
    "        \n",
    "        x_agg = torch.cat(agg_batch, dim=0)\n",
    "                \n",
    "        return x, x_agg\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create separate loss function\n",
    "Calculate loss on change samples, all samples, and non-change samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAE_Change(prediction, actual):\n",
    "    # Compute a tensor that indicates which elements have changed\n",
    "    change_mask = torch.any(actual[:, :-1, :] != actual[:, 1:, :], dim=-1)\n",
    "    sample_indices, _ = torch.where(change_mask)\n",
    "    \n",
    "    # Check if any change samples are present\n",
    "    if sample_indices.numel() == 0:\n",
    "        return torch.tensor(0.0)\n",
    "    \n",
    "    # Actual and predicted change\n",
    "    actual_change = actual[sample_indices]\n",
    "    predicted_change = prediction[sample_indices]\n",
    "\n",
    "    # Calculate MAE of the changes\n",
    "#     mae = torch.mean(torch.abs(predicted_change - actual_change))\n",
    "    mae = nn.L1Loss()(predicted_change, actual_change)\n",
    "\n",
    "    return mae\n",
    "\n",
    "def MAE_NoChange(prediction, actual):\n",
    "    # Compute a tensor that indicates which elements have changed\n",
    "    change_mask = torch.any(actual[:, :-1, :] != actual[:, 1:, :], dim=-1)\n",
    "    sample_indices, _ = torch.where(change_mask)\n",
    "    \n",
    "    # Check if any change samples are present\n",
    "    if sample_indices.numel() == 0:\n",
    "        return torch.tensor(0.0)\n",
    "    \n",
    "    # Actual and predicted \n",
    "    actual_nochange = actual[~sample_indices]\n",
    "    predicted_nochange = prediction[~sample_indices]\n",
    "\n",
    "    # Calculate MAE of the non-changes\n",
    "    mae = nn.L1Loss()(predicted_nochange, actual_nochange)\n",
    "\n",
    "    return mae\n",
    "\n",
    "# Combined loss\n",
    "class CombinedLoss(nn.Module):\n",
    "    def __init__(self, change_weight):\n",
    "        super().__init__()\n",
    "        self.change_weight = change_weight\n",
    "        self.l1_loss = nn.L1Loss()\n",
    "\n",
    "    def forward(self, prediction, actual):\n",
    "        # Loss of all samples\n",
    "        l1_loss = self.l1_loss(prediction, actual)\n",
    "        \n",
    "        # Loss of samples with no change\n",
    "        no_change_loss = MAE_NoChange(prediction, actual)\n",
    "\n",
    "        # Loss of samples with change\n",
    "        change_loss = MAE_Change(prediction, actual)\n",
    "        \n",
    "        # Check if change loss is more than 0. If not, full weight on all samples\n",
    "        if torch.all(change_loss == 0):\n",
    "            weight = 0.0\n",
    "        else:\n",
    "            weight = self.change_weight\n",
    "\n",
    "        # Combine losses with specified weights\n",
    "        combined_loss = (1 - weight) * l1_loss + weight * change_loss\n",
    "\n",
    "        return combined_loss\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train/run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make lists to retain loss\n",
    "losses_train_epochs = []\n",
    "losses_test_epochs = []\n",
    "\n",
    "# Retain prediction at lowest loss\n",
    "best_loss = float(\"inf\")\n",
    "current_loss = float(\"inf\")\n",
    "best_epoch = 0\n",
    "best_layer = 0\n",
    "\n",
    "# Model tested:\n",
    "modeltype = \"LSTM\"\n",
    "\n",
    "# Number of stacked layers (just break operation otherwise)\n",
    "for layer in range(2):\n",
    "    \n",
    "    # Stop iterating if layer did not find better loss\n",
    "    if layer - best_layer > 1:\n",
    "        break\n",
    "\n",
    "    # At the start, initialise with either LSTM or RF\n",
    "    if layer == 0:\n",
    "        \n",
    "        if modeltype == \"LSTM\":          \n",
    "            # Use synth and or actual data as start data set\n",
    "            X_dataset = train_dataset_norm_regressed\n",
    "            Y_dataset = LSTM_vali_dataset_norm\n",
    "            \n",
    "            # Test split\n",
    "            train_size = int(0.8 * training_X_norm.size(0)) # was 0.5\n",
    "            test_size = training_X_norm.size(0) - train_size\n",
    "            X_dataset, test_dataset = random_split(X_dataset, [train_size, test_size])\n",
    "            \n",
    "            # Input length to start with\n",
    "            start_input_length = training_X_norm.size(-1)\n",
    "        \n",
    "        elif modeltype == \"RF\":\n",
    "            # Use synth and or actual data as start data set\n",
    "            X_dataset = train_dataset_norm_regressed\n",
    "            Y_dataset = RF_vali_dataset_norm\n",
    "            \n",
    "            # Test split\n",
    "            train_size = int(0.8 * training_X_norm.size(0)) # was 0.5\n",
    "            test_size = training_X_norm.size(0) - train_size\n",
    "            X_dataset, test_dataset = random_split(X_dataset, [train_size, test_size])\n",
    "            \n",
    "            # Input length to start with\n",
    "            start_input_length = training_X_norm.size(-1)\n",
    "            \n",
    "        else:\n",
    "            print(\"No valid model input.\")\n",
    "            break\n",
    "\n",
    "        # Initialise loss function    \n",
    "        change_weight = 0.3 # between 0-1, the higher, the more focused on change \n",
    "        loss_fn = CombinedLoss(change_weight=change_weight)\n",
    "#         loss_fn = nn.L1Loss()\n",
    "        \n",
    "        # Initialise model and optimizer\n",
    "        model = BiLSTMModel(input_size = start_input_length, hidden_size = 256, output_size = 7)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.001) # was 0.0003\n",
    "\n",
    "        # Create a DataLoader for the training set and validation sets (specify batch size)\n",
    "        train_loader = torch.utils.data.DataLoader(X_dataset, batch_size=256, shuffle=True) # was 128\n",
    "        test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=256, shuffle=True)\n",
    "        vali_loader = torch.utils.data.DataLoader(Y_dataset, batch_size=256, shuffle=False) \n",
    "\n",
    "        # Epochs at start\n",
    "        num_epochs = 100\n",
    "        \n",
    "        # Set the model to training mode \n",
    "        model.zero_grad()\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "    else:\n",
    "\n",
    "        # At the next layers, use newly created data sets\n",
    "        X_dataset = new_train_dataset\n",
    "        Y_dataset = new_vali_dataset \n",
    "        \n",
    "        # Test split\n",
    "        train_size = int(0.8 * new_input_size) # was 0.5\n",
    "        test_size = new_input_size - train_size\n",
    "        X_dataset, test_dataset = random_split(X_dataset, [train_size, test_size])\n",
    "        \n",
    "        # Create a DataLoader for the training set and validation sets (specify batch size)\n",
    "        train_loader = torch.utils.data.DataLoader(X_dataset, batch_size=256, shuffle=True) # was 128\n",
    "        test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=256, shuffle=True)\n",
    "        vali_loader = torch.utils.data.DataLoader(Y_dataset, batch_size=256, shuffle=False) \n",
    "        \n",
    "        # Epochs\n",
    "        num_epochs = 200\n",
    "        \n",
    "        # Re-initialise model and remove gradients from previous layer\n",
    "        model = BiLSTMModel(input_size = new_input_length, hidden_size = 256, output_size = 7) \n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.001)\n",
    "        model.zero_grad()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    # Loop over the training data\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        # Progress\n",
    "        print(\"\\rAt epoch: {}/{}, Loss: {}, Best loss: {} (obtained at epoch {}, layer {})\".format(epoch, \n",
    "                                                                                num_epochs, round(current_loss, 3), round(best_loss, 3),\n",
    "                                                                                best_epoch, best_layer+1), end='\\r')\n",
    "\n",
    "        # Loss per epoch\n",
    "        epoch_trainloss = []\n",
    "        epoch_testloss = []\n",
    "        \n",
    "        # Predictions per epoch\n",
    "        epoch_pred_agg = []\n",
    "        epoch_pred_dense = []\n",
    "        epoch_pred_tensor = []\n",
    "        epoch_pred_dense_tensor = []\n",
    "        epoch_actual = []\n",
    "        epoch_actual_tensor = []\n",
    "        epoch_actual_dense_tensor = []\n",
    "        \n",
    "        # Save training input\n",
    "        train_input = []\n",
    "        \n",
    "        # Save train target\n",
    "        train_target = []\n",
    "        \n",
    "        # Start model training\n",
    "        model.train() \n",
    "        \n",
    "        # Loop over the training set\n",
    "        for X, Y in train_loader:\n",
    "            \n",
    "            # Check if Y is already a sequence of 92 (regressed), or repeat it into 92\n",
    "            if Y.shape[1] < 91:\n",
    "                Y_dense = Y.repeat_interleave(repeats=23, dim=1)\n",
    "            else:\n",
    "                Y_dense = Y\n",
    "\n",
    "            # Clear the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Compute the loss\n",
    "            Y_pred, Y_pred_agg = model(X)\n",
    "            loss = loss_fn(Y_pred, Y_dense)\n",
    "\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "\n",
    "            # Update the parameters\n",
    "            optimizer.step()\n",
    "\n",
    "            # Append the loss to the lists\n",
    "            epoch_trainloss.append(loss.item())\n",
    "\n",
    "            # Save input for next layer\n",
    "            X_without_prev_lcf = X[:, :, :-7]\n",
    "            train_input.append(torch.cat([X_without_prev_lcf, Y_pred], dim=-1))\n",
    "            train_target.append(Y)\n",
    "        \n",
    "        # Save test and vali input\n",
    "        test_input = []\n",
    "        vali_input = []\n",
    "        \n",
    "        # Save test and vali target\n",
    "        test_target = []\n",
    "        vali_target = []\n",
    "        \n",
    "        # Deactivatite autograd engine when looping over validation set\n",
    "        with torch.no_grad():\n",
    "\n",
    "            # Set the model to evaluation mode\n",
    "            model.eval()\n",
    "            \n",
    "             # Loop over the test data set\n",
    "            for X, Y in test_loader:\n",
    "\n",
    "                # Check if Y is already a sequence of 92 (regressed), or repeat it into 92\n",
    "                if Y.shape[1] < 91:\n",
    "                    Y_dense = Y.repeat_interleave(repeats=23, dim=1)\n",
    "                else:\n",
    "                    Y_dense = Y\n",
    "\n",
    "                # Compute the loss\n",
    "                Y_pred, Y_pred_agg = model(X)\n",
    "                loss = loss_fn(Y_pred, Y_dense)\n",
    "\n",
    "                # Append the loss to the list\n",
    "                epoch_testloss.append(loss.item())\n",
    "\n",
    "                # Save input for next layer\n",
    "                X_without_prev_lcf = X[:, :, :-7]\n",
    "                test_input.append(torch.cat([X_without_prev_lcf, Y_pred], dim=-1))\n",
    "                test_target.append(Y)\n",
    "        \n",
    "            # Loop over the vali data set\n",
    "            for X, Y in vali_loader:\n",
    "                \n",
    "                # Validation data was not regressed\n",
    "                Y_dense = Y.repeat_interleave(repeats=23, dim=1)\n",
    "\n",
    "                # Make prediction    \n",
    "                Y_pred, Y_pred_agg = model(X)\n",
    "                \n",
    "                # Store predictions for batch\n",
    "                Y_pred_dense_list = [x.tolist() for x in Y_pred]\n",
    "                Y_pred_agg_list = [x.tolist() for x in Y_pred_agg]\n",
    "                Y_list = [x.tolist() for x in Y]\n",
    "\n",
    "                # Add batch prediction to list \n",
    "                epoch_pred_dense.append(Y_pred_dense_list)\n",
    "                epoch_pred_agg.append(Y_pred_agg_list)\n",
    "                epoch_actual.append(Y_list)\n",
    "\n",
    "                # Retain tensors per batch\n",
    "                epoch_pred_dense_tensor.append(Y_pred)\n",
    "                epoch_actual_dense_tensor.append(Y_dense)\n",
    "                epoch_pred_tensor.append(Y_pred_agg)\n",
    "                epoch_actual_tensor.append(Y)\n",
    "\n",
    "                # Save input for next layer\n",
    "                X_without_prev_lcf = X[:, :, :-7]\n",
    "                vali_input.append(torch.cat([X_without_prev_lcf, Y_pred], dim=-1))\n",
    "                vali_target.append(Y)\n",
    "        \n",
    "        # Retain tensors for whole epoch for statistics\n",
    "        epoch_pred_dense_tensor = torch.cat(epoch_pred_dense_tensor, dim=0)\n",
    "        epoch_pred_tensor = torch.cat(epoch_pred_tensor, dim=0)\n",
    "        epoch_actual_tensor = torch.cat(epoch_actual_tensor, dim=0)\n",
    "        epoch_actual_dense_tensor = torch.cat(epoch_actual_dense_tensor, dim=0)\n",
    "    \n",
    "        # Add epoch losses to total loss list \n",
    "        losses_train_epochs.append(epoch_trainloss)\n",
    "        losses_test_epochs.append(epoch_testloss)\n",
    "\n",
    "        # Retain new inputs/targets\n",
    "        # Training\n",
    "        train_input = torch.cat(train_input, dim=0)\n",
    "        train_target = torch.cat(train_target, dim=0)\n",
    "        \n",
    "        # Test\n",
    "        test_input = torch.cat(test_input, dim=0)\n",
    "        test_target = torch.cat(test_target, dim=0)\n",
    "        \n",
    "        # Vali\n",
    "        vali_input = torch.cat(vali_input, dim=0)\n",
    "        vali_target = torch.cat(vali_target, dim=0)\n",
    "        \n",
    "        # Current loss\n",
    "        current_loss = sum(epoch_testloss) / len(test_loader)\n",
    "        \n",
    "        if epoch == 0 and (layer == 1 or layer == 2 or layer == 3 or layer == 4 or layer == 5):\n",
    "            best_loss = current_loss\n",
    "        \n",
    "        # Check if the current epoch achieved the lowest observed loss, if so, save epoch prediction\n",
    "        if current_loss < best_loss:\n",
    "            # Update best parameters\n",
    "            best_loss = current_loss\n",
    "            best_pred = epoch_pred_agg\n",
    "            best_pred_dense = epoch_pred_dense\n",
    "            best_actual = epoch_actual\n",
    "            best_epoch = epoch\n",
    "            best_layer = layer\n",
    "\n",
    "            # Save prediction tensors\n",
    "            # Training\n",
    "            best_train_input = train_input\n",
    "            best_train_target = train_target\n",
    "            \n",
    "            # Test\n",
    "            best_test_input = test_input\n",
    "            best_test_target = test_target\n",
    "            \n",
    "            # Validation\n",
    "            best_vali_input = vali_input\n",
    "            best_vali_target = vali_target\n",
    "            \n",
    "            # Detach from graph for next layer\n",
    "            # Training\n",
    "            best_train_input = best_train_input.detach()\n",
    "            best_train_target = best_train_target.detach()\n",
    "            \n",
    "            # Test\n",
    "            best_test_input = best_test_input.detach()\n",
    "            best_test_target = best_test_target.detach()\n",
    "            \n",
    "            # Validation\n",
    "            best_vali_input = best_vali_input.detach() \n",
    "            best_vali_target = best_vali_target.detach()\n",
    "            \n",
    "            # Normalise lcf\n",
    "            vali_lcf, orig_vali_input = best_vali_input[:, :, -len(targets):], best_vali_input[:, :, :-7]\n",
    "            train_lcf, orig_train_input = best_train_input[:, :, -len(targets):], best_train_input[:, :, :-7]\n",
    "            test_lcf, orig_test_input = best_test_input[:, :, -len(targets):], best_test_input[:, :, :-7]\n",
    "            train_mean = train_lcf.mean(dim=0)\n",
    "            train_std = train_lcf.std(dim=0)\n",
    "            train_lcf = (train_lcf - train_mean) / train_std\n",
    "            test_lcf = (test_lcf - train_mean) / train_std\n",
    "            vali_lcf = (vali_lcf - train_mean) / train_std\n",
    "            \n",
    "            # Cocatenate back\n",
    "            best_train_input_norm = torch.cat([orig_train_input, train_lcf], dim=-1)\n",
    "            best_test_input_norm = torch.cat([orig_test_input, test_lcf], dim=-1)\n",
    "            best_vali_input_norm = torch.cat([orig_vali_input, vali_lcf], dim=-1)\n",
    "            \n",
    "            # Concatenate train and test\n",
    "            best_traintest_input_norm = torch.cat([best_train_input_norm, best_test_input_norm], dim=0)\n",
    "            best_traintest_target = torch.cat([best_train_target, best_test_target], dim=0)\n",
    "            \n",
    "            # Create data sets\n",
    "            new_train_dataset = TensorDataset(best_traintest_input_norm, best_traintest_target)\n",
    "            new_vali_dataset = TensorDataset(best_vali_input_norm, best_vali_target)\n",
    "            new_input_length = best_traintest_input_norm.size(-1)\n",
    "            new_input_size = best_traintest_input_norm.size(0)\n",
    "    \n",
    "print(\"\\n\", \"Done\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### See losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average loss per epoch\n",
    "ltrain_epochs = []\n",
    "for epoch_list in losses_train_epochs:\n",
    "  epoch_avg = sum(epoch_list) / len(train_loader)\n",
    "  ltrain_epochs.append(epoch_avg)\n",
    "\n",
    "ltest_epochs = []\n",
    "for epoch_list in losses_test_epochs:\n",
    "  epoch_avg = sum(epoch_list) / len(test_loader)\n",
    "  ltest_epochs.append(epoch_avg)\n",
    "\n",
    "# Print epoch achieving minimum vali loss\n",
    "min_value = min(ltest_epochs)\n",
    "min_index = ltest_epochs.index(min_value)\n",
    "\n",
    "print(\"The lowest loss:\", round(min_value,3), \"is found at epoch:\", min_index, \"\\n\")\n",
    "\n",
    "# Plot the losses over time\n",
    "plt.plot(ltrain_epochs, label=\"Training loss\")\n",
    "plt.plot(ltest_epochs, label=\"Validation loss\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Average loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### See predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from statistics import mean\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# # Make lists of predictions and actual fractions (reference)\n",
    "nested_pred = best_pred # results from the epoch with the minimum loss is taken\n",
    "nested_actual = best_actual\n",
    "\n",
    "unnested_pred = []\n",
    "for data in nested_pred:\n",
    "  for batch in data:\n",
    "    for timestep in batch:\n",
    "      for target in range(len(timestep)):\n",
    "        unnested_pred.append(timestep[target])\n",
    "\n",
    "unnested_actual = []\n",
    "for data in nested_actual:\n",
    "  for batch in data:\n",
    "    for timestep in batch:\n",
    "      for target in range(len(timestep)):\n",
    "        unnested_actual.append(timestep[target])\n",
    "\n",
    "# These lists contain output for entire predictions \n",
    "# Now retain lists for each class\n",
    "pred_class = {}\n",
    "true_class = {}\n",
    "\n",
    "# Also retain dense predictions\n",
    "pred_dense_class = {}\n",
    "nested_dense_pred = best_pred_dense\n",
    "\n",
    "unnested_dense_pred = []\n",
    "for data in nested_dense_pred:\n",
    "  for batch in data:\n",
    "    for timestep in batch:\n",
    "      for target in range(len(timestep)):\n",
    "        unnested_dense_pred.append(timestep[target])\n",
    "\n",
    "# Initialize lists for each class in predictions\n",
    "for i in range(len(targets)):\n",
    "  pred_class[f'{targets[i]}'] = unnested_pred[i::len(targets)]\n",
    "\n",
    "# And dense\n",
    "for i in range(len(targets)):\n",
    "  pred_dense_class[f'{targets[i]}'] = unnested_dense_pred[i::len(targets)]\n",
    "\n",
    "# Initialize lists for each class in reference data\n",
    "for i in range(len(targets)):\n",
    "  true_class[f'{targets[i]}'] = unnested_actual[i::len(targets)]\n",
    "\n",
    "RMSEavg = 0\n",
    "MAEavg = 0\n",
    "\n",
    "# Plot the lists as graphs\n",
    "\n",
    "# Loop through the data and plot the actual and predicted values\n",
    "for i in range(len(targets)):\n",
    "    # Get the data for the current class\n",
    "    true = true_class[f'{targets[i]}']\n",
    "    predicted = pred_class[f'{targets[i]}']\n",
    "\n",
    "    # Define the x-axis data as a range of values from 0 to the length of the data\n",
    "    x = range(len(true))\n",
    "\n",
    "    # Create a new figure\n",
    "    fig = plt.figure(i)\n",
    "\n",
    "    # Create a figure with certain size\n",
    "    fig = plt.figure(figsize=(20, 3))\n",
    "\n",
    "    # Create axes\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "    # Plot the actual and predicted values\n",
    "    ax.plot(x, true, label='Actual')\n",
    "    ax.plot(x, predicted, label='Predicted')\n",
    "\n",
    "    # Add a legend\n",
    "    ax.legend()\n",
    "\n",
    "    # Set the title using the class name\n",
    "    var_name = f'{targets[i]}'\n",
    "    ax.set_title(var_name)\n",
    "\n",
    "    # Show the figure\n",
    "    plt.show()\n",
    "\n",
    "    # Print RMSE / MAE\n",
    "    rmse = mean_squared_error(predicted, true) ** 0.5\n",
    "    RMSEavg = RMSEavg + rmse\n",
    "    print(f'RMSE for {var_name}: {round(rmse, 2)}')\n",
    "\n",
    "    difference = [abs(predicted - true) for predicted, true in zip(predicted, true)]\n",
    "    mae = mean(difference)\n",
    "    MAEavg = MAEavg + mae\n",
    "    print(f'MAE for {var_name}: {round(mae, 2)}')\n",
    "\n",
    "print(\"\\n\")\n",
    "RMSEavg = RMSEavg / len(targets)\n",
    "MAEavg = MAEavg / len(targets)\n",
    "\n",
    "print(f'Average RMSE is {round(RMSEavg, 2)} and average MAE is {round(MAEavg, 2)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create corresponding ID lists\n",
    "Because of NaN values we have to recreate the ID lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor_Agg_IDs and tensor_Dense_IDs\n",
    "# IDs_aggregated = ['sample_id', 'location_id', 'reference_year', 'x', 'y']\n",
    "# IDs_dense = ['location_id', 'date', 'x', 'y']\n",
    "\n",
    "# Mention which IDs should be taken\n",
    "predicts = \"RF\"\n",
    "\n",
    "if predicts == \"RF\":\n",
    "    tensor_Agg = tensor_Agg_IDs\n",
    "    tensor_Dense = tensor_Dense_IDs\n",
    "else:\n",
    "    tensor_Agg = LSTM_tensor_Agg_IDs\n",
    "    tensor_Dense = LSTM_tensor_Dense_IDs\n",
    "\n",
    "Agg_dict = {}\n",
    "Dense_dict = {}\n",
    "\n",
    "for i, id_name in enumerate(IDs_aggregated):\n",
    "    id_list = tensor_Agg[:, :, i].flatten().tolist()\n",
    "    Agg_dict[id_name] = id_list\n",
    "\n",
    "for i, id_name in enumerate(IDs_dense):\n",
    "    id_list = tensor_Dense[:, :, i].flatten().tolist()\n",
    "    Dense_dict[id_name] = id_list\n",
    "   \n",
    "print(\"Let's check if the created ID lists have the proper length:\")\n",
    "print(len(pred_class[f'{targets[1]}']), len(Agg_dict[f'{IDs_aggregated[1]}']))\n",
    "print(len(pred_dense_class[f'{targets[1]}']), len(Dense_dict[f'{IDs_aggregated[1]}']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join predictions with IDs and write to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add IDs (vali data was not shuffled so can add like this)\n",
    "import pandas as pd\n",
    "\n",
    "pred_df = pd.DataFrame.from_dict(Agg_dict)\n",
    "dense_pred_df = pd.DataFrame.from_dict(Dense_dict)\n",
    "\n",
    "# Adds predictions to df \n",
    "for i in range(len(targets)):\n",
    "    data = pred_class[f'{targets[i]}']\n",
    "    data_dense = pred_dense_class[f'{targets[i]}']\n",
    "\n",
    "    pred_df[targets[i]] = data \n",
    "    dense_pred_df[targets[i]] = data_dense \n",
    "\n",
    "# Show df\n",
    "pred_df.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write both dense and dense -> aggregated predictions to file\n",
    "\n",
    "pred_df.to_csv('Output/RF_PostLSTM_dense_to_agg.csv')\n",
    "dense_pred_df.to_csv('Output/RF_PostLSTM_dense.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
