{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Unnamed: 0' 'location_id' 'x' 'y' 'date' 'b1' 'b2' 'b3' 'b4' 'b5' 'b6'\n",
      " 'b7'] ['Unnamed: 0' 'sample_id' 'location_id' 'validation_id' 'reference_year'\n",
      " 'x' 'y' 'bare' 'crops' 'grassland' 'shrub' 'tree' 'urban_built_up'\n",
      " 'water' 'dominant_lc']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('/mnt/guanabana/raid/home/slomp006')\n",
    "\n",
    "# Upload created input and targets to server\n",
    "# Read dense data\n",
    "train_inputs = pd.read_csv('Input/Dense/dense_train_input.csv') \n",
    "train_targets = pd.read_csv('Input/Dense/dense_train_targets.csv') \n",
    "\n",
    "vali_inputs = pd.read_csv('Input/Dense/dense_vali_input.csv') \n",
    "vali_targets = pd.read_csv('Input/Dense/dense_vali_targets.csv') \n",
    "\n",
    "print(vali_inputs.columns.values,vali_targets.columns.values)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create data from input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train X contained nan values: False , new train X contains nan values: False\n",
      "Old shape of train X: torch.Size([33540, 92, 9]) New shape:  torch.Size([33540, 92, 9]) \n",
      "\n",
      "Train Y contained nan values: False , new train Y contains nan values: False\n",
      "Old shape of train Y: torch.Size([33540, 4, 7]) New shape:  torch.Size([33540, 4, 7]) \n",
      "\n",
      "vali X contained nan values: True , new vali X contains nan values: False\n",
      "Old shape of vali X: torch.Size([30712, 92, 9]) New shape:  torch.Size([30674, 92, 9]) \n",
      "\n",
      "vali Y contained nan values: False , new vali Y contains nan values: False\n",
      "Old shape of vali Y: torch.Size([30712, 4, 7]) New shape:  torch.Size([30674, 4, 7]) \n",
      "\n",
      "ID vali contained nan values: False , new ID vali contains nan values: False\n",
      "Old shape of ID vali: torch.Size([30712, 4, 6]) New shape:  torch.Size([30674, 4, 6])\n",
      "(ID vali shape should be similar to vali Y (will be joined later))\n"
     ]
    }
   ],
   "source": [
    "# Input features (make sure they are existing columns)\n",
    "vars = ['x', 'y', 'b1', 'b2', 'b3', 'b4', 'b5', 'b6', 'b7']\n",
    "\n",
    "# Output features (targets) (make sure they are existing columns)\n",
    "targets = ['bare', 'crops',\n",
    "       'grassland', 'shrub', 'tree', 'urban_built_up', 'water']\n",
    "\n",
    "# Save IDs to later join them again\n",
    "IDs = ['sample_id', 'location_id', 'validation_id', 'reference_year',\n",
    "        'x', 'y']\n",
    "\n",
    "# Create X (input features) in loop\n",
    "trainX_list = []\n",
    "valiX_list = []\n",
    "\n",
    "for colname in vars: \n",
    "  # Get column of feature\n",
    "  col_train = train_inputs[colname]\n",
    "  col_vali = vali_inputs[colname]\n",
    "\n",
    "  # Create train and vali tensor\n",
    "  var_train = torch.tensor(col_train.values).view(-1, 92, 1) # sequence length now 92 (number of acq. dates in 2015-2018)\n",
    "  var_vali = torch.tensor(col_vali.values).view(-1, 92, 1)\n",
    "\n",
    "  # Convert to float32 (used in LSTM)\n",
    "  var_train = var_train.to(dtype=torch.float32)\n",
    "  var_vali = var_vali.to(dtype=torch.float32)\n",
    "\n",
    "  # Append to lists\n",
    "  trainX_list.append(var_train)\n",
    "  valiX_list.append(var_vali)\n",
    "\n",
    "# Do the same for Y (targets)\n",
    "trainY_list = []\n",
    "valiY_list = []\n",
    "\n",
    "for colname in targets: \n",
    "  # Get column of feature\n",
    "  col_train = train_targets[colname]\n",
    "  col_vali = vali_targets[colname]\n",
    "\n",
    "  # Create train and vali tensor\n",
    "  var_train = torch.tensor(col_train.values).view(-1, 4, 1)\n",
    "  var_vali = torch.tensor(col_vali.values).view(-1, 4, 1)\n",
    "\n",
    "  # Convert to float32 (used in LSTM)\n",
    "  var_train = var_train.to(dtype=torch.float32)\n",
    "  var_vali = var_vali.to(dtype=torch.float32)\n",
    "\n",
    "  # Append to lists\n",
    "  trainY_list.append(var_train)\n",
    "  valiY_list.append(var_vali)\n",
    "\n",
    "# Save IDs in list\n",
    "ID_list = []\n",
    "    \n",
    "for colname in IDs:\n",
    "  # Get column of ID\n",
    "  col_ID = vali_targets[colname]\n",
    "\n",
    "  # Create tensor\n",
    "  ID_tensor = torch.tensor(col_ID.values).view(-1, 4, 1)\n",
    "\n",
    "  # Convert to float32 (used in LSTM)\n",
    "  ID_tensor = ID_tensor.to(dtype=torch.float32)\n",
    "\n",
    "  # Append to list\n",
    "  ID_list.append(ID_tensor)\n",
    "    \n",
    "# We now have multiple features as tensors but we want them as one. So concatenate the tensors along the last dimension (2 = -1)\n",
    "X_train = torch.cat(trainX_list, dim=2)\n",
    "X_vali = torch.cat(valiX_list, dim=2)\n",
    "Y_train = torch.cat(trainY_list, dim=2)\n",
    "Y_vali = torch.cat(valiY_list, dim=2)\n",
    "\n",
    "ID_vali = torch.cat(ID_list, dim=2)\n",
    "\n",
    "# Now check if any tensors contain nan values and if so remove them (entire matrix). LSTM will not work (correctly) with nan values.\n",
    "X_train_old = X_train\n",
    "X_vali_old = X_vali\n",
    "Y_train_old = Y_train\n",
    "Y_vali_old = Y_vali\n",
    "ID_vali_old = ID_vali\n",
    "\n",
    "# create an empty mask\n",
    "mask = None\n",
    "\n",
    "# If X_train contains nan, apply mask to Y_train and vice versa. Same applies for X and Y_vali.\n",
    "if torch.isnan(X_train).any():\n",
    "    mask = torch.isnan(X_train).any(dim=1).any(dim=1)\n",
    "    X_train = X_train[~mask]\n",
    "    Y_train = Y_train[~mask] \n",
    "if torch.isnan(Y_train).any():\n",
    "    mask = torch.isnan(Y_train).any(dim=1).any(dim=1) \n",
    "    Y_train = Y_train[~mask]\n",
    "    X_train = X_train[~mask]\n",
    "if torch.isnan(X_vali).any():\n",
    "    mask = torch.isnan(X_vali).any(dim=1).any(dim=1) \n",
    "    X_vali = X_vali[~mask]\n",
    "    Y_vali = Y_vali[~mask]\n",
    "    ID_vali = ID_vali[~mask]\n",
    "if torch.isnan(Y_vali).any():\n",
    "    mask = torch.isnan(Y_vali).any(dim=1).any(dim=1) \n",
    "    Y_vali = Y_vali[~mask]\n",
    "    X_vali = X_vali[~mask]\n",
    "    ID_vali = ID_vali[~mask]\n",
    "\n",
    "# Check final tensors (including shape)\n",
    "print(\"Train X contained nan values:\", torch.isnan(X_train_old).any().item(), \", new train X contains nan values:\", torch.isnan(X_train).any().item())\n",
    "print(\"Old shape of train X:\", X_train_old.shape, \"New shape: \", X_train.shape, \"\\n\")\n",
    "print(\"Train Y contained nan values:\", torch.isnan(Y_train_old).any().item(), \", new train Y contains nan values:\", torch.isnan(Y_train).any().item())\n",
    "print(\"Old shape of train Y:\", Y_train_old.shape, \"New shape: \", Y_train.shape, \"\\n\")\n",
    "\n",
    "print(\"vali X contained nan values:\", torch.isnan(X_vali_old).any().item(), \", new vali X contains nan values:\", torch.isnan(X_vali).any().item())\n",
    "print(\"Old shape of vali X:\", X_vali_old.shape, \"New shape: \", X_vali.shape, \"\\n\")\n",
    "print(\"vali Y contained nan values:\", torch.isnan(Y_vali_old).any().item(), \", new vali Y contains nan values:\", torch.isnan(Y_vali).any().item())\n",
    "print(\"Old shape of vali Y:\", Y_vali_old.shape, \"New shape: \", Y_vali.shape, \"\\n\")\n",
    "print(\"ID vali contained nan values:\", torch.isnan(ID_vali_old).any().item(), \", new ID vali contains nan values:\", torch.isnan(ID_vali).any().item())\n",
    "print(\"Old shape of ID vali:\", ID_vali_old.shape, \"New shape: \", ID_vali.shape)\n",
    "print(\"(ID vali shape should be similar to vali Y (will be joined later))\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of original samples: 33540 \n",
      "\n",
      "Number of original samples per class (where class is > 0): \n",
      " bare: 5412 crops: 7159 grassland: 22978 shrub: 16868 tree: 14736 urban_built_up: 2283 water: 3261\n",
      "Number of original samples per class (where class is == 100): \n",
      " bare: 364 crops: 2102 grassland: 4988 shrub: 670 tree: 1673 urban_built_up: 9 water: 1784 \n",
      "\n",
      "Number of samples after upsampling: 43563 \n",
      "\n",
      "Number of samples per class (where class is represented > 0): \n",
      " bare: 8488 crops: 11071 grassland: 30530 shrub: 23436 tree: 21928 urban_built_up: 12306 water: 3889\n",
      "Number of original samples per class (where class is == 100): \n",
      " bare: 364 crops: 2102 grassland: 4988 shrub: 670 tree: 1673 urban_built_up: 936 water: 1784\n"
     ]
    }
   ],
   "source": [
    "# Indices:   0   ,    1   ,       2    ,    3    ,   4  ,       5         ,    6\n",
    "targets = ['bare', 'crops', 'grassland', 'shrub', 'tree', 'urban_built_up', 'water']\n",
    "\n",
    "# Clone original data\n",
    "X_new, Y_new = X_train.clone(), Y_train.clone()\n",
    "\n",
    "# See length of original samples\n",
    "print(\"Number of original samples:\", len(X_train), \"\\n\")\n",
    "class_counts = [len(Y_new[Y_new[:, -1, i] != 0]) for i in range(len(targets))]\n",
    "class_counts_100 = [len(Y_new[Y_new[:, -1, i] == 100]) for i in range(len(targets))]\n",
    "print(\"Number of original samples per class (where class is > 0):\", \"\\n\", \n",
    "      *[f\"{targets[i]}: {class_counts[i]}\" for i in range(len(targets))])\n",
    "print(\"Number of original samples per class (where class is == 100):\", \"\\n\", \n",
    "      *[f\"{targets[i]}: {class_counts_100[i]}\" for i in range(len(targets))], \"\\n\")\n",
    "\n",
    "# Function to upsample classes where value is > 0 (thus every sample where class is represented)\n",
    "def upsample(X, Y, i, n):\n",
    "    idx = Y[:, -1, i] != 0 # -1 to account for one that is already in the data set\n",
    "    X_sub = X[idx].repeat(n-1, 1, 1)\n",
    "    Y_sub = Y[idx].repeat(n-1, 1, 1)\n",
    "    return X_sub, Y_sub\n",
    "\n",
    "# Function to only upsample classes where value = 100 (thus every sample where class is 100)\n",
    "def upsample100(X, Y, i, n):\n",
    "    idx = Y[:, -1, i] == 100\n",
    "    X_sub = X[idx].repeat(n-1, 1, 1)\n",
    "    Y_sub = Y[idx].repeat(n-1, 1, 1)\n",
    "    return X_sub, Y_sub\n",
    "\n",
    "# Upsample all urban cases\n",
    "urban_X, urban_Y = upsample(X_new, Y_new, 5, 5)\n",
    "\n",
    "# Upsample urban cases where value is 100\n",
    "urban_100_X, urban_100_Y = upsample100(X_new, Y_new, 5, 100)\n",
    "\n",
    "# Create upsampled training data\n",
    "X_new = torch.cat([X_new, urban_X, urban_100_X], dim=0)\n",
    "Y_new = torch.cat([Y_new, urban_Y, urban_100_Y], dim=0)\n",
    "\n",
    "# Print new lengths\n",
    "print(\"Number of samples after upsampling:\", len(X_new), \"\\n\")\n",
    "new_class_counts = [len(Y_new[Y_new[:, -1, i] != 0]) for i in range(len(targets))]\n",
    "new_class_counts_100 = [len(Y_new[Y_new[:, -1, i] == 100]) for i in range(len(targets))]\n",
    "print(\"Number of samples per class (where class is represented > 0):\", \"\\n\", \n",
    "      *[f\"{targets[i]}: {new_class_counts[i]}\" for i in range(len(targets))])\n",
    "print(\"Number of original samples per class (where class is == 100):\", \"\\n\", \n",
    "      *[f\"{targets[i]}: {new_class_counts_100[i]}\" for i in range(len(targets))])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regress target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RegressSamples(originalX, originalY):    \n",
    "    \n",
    "    # Clone original tensors\n",
    "    test_Y = originalY.clone().detach()\n",
    "    test_X = originalX.clone().detach()\n",
    "\n",
    "    # Save regressed tensor\n",
    "    regressed_tensor = []\n",
    "\n",
    "    # Loop over samples\n",
    "    for sample in range(test_Y.shape[0]):\n",
    "\n",
    "        # Progress\n",
    "        print(\"\\rRegressing sample: {}/{}\".format(sample, test_Y.shape[0]), end='\\r')\n",
    "\n",
    "        # Create output tensor sample for sample      \n",
    "        out = torch.zeros(1, 92, 7)\n",
    "\n",
    "        # If southern hemisphere, place fractions at first months (important, second indice need to translate to Y coord!!)      \n",
    "        if (test_X[sample, :, 1] < 0).all():\n",
    "\n",
    "            out[:, 0:5, :] = test_Y[sample, 0, :].unsqueeze(0).unsqueeze(1).repeat_interleave(5, dim=1)\n",
    "            out[:, 23:28, :] = test_Y[sample, 1, :].unsqueeze(0).unsqueeze(1).repeat_interleave(5, dim=1)\n",
    "            out[:, 46:51, :] = test_Y[sample, 2, :].unsqueeze(0).unsqueeze(1).repeat_interleave(5, dim=1)\n",
    "            out[:, 69:, :] = test_Y[sample, 3, :].unsqueeze(0).unsqueeze(1).repeat_interleave(23, dim=1)\n",
    "\n",
    "            diff1 = (out[:, 23, :] - out[:, 4, :]).unsqueeze(1)\n",
    "            diff2 = (out[:, 46, :] - out[:, 27, :]).unsqueeze(1)\n",
    "            diff3 = (out[:, 69, :] - out[:, 50, :]).unsqueeze(1)\n",
    "\n",
    "            for diff in range(3):\n",
    "\n",
    "                if diff == 0:\n",
    "                    diff_timesteps = 23-5\n",
    "                    start_timestep = 5-1\n",
    "                    diff_values = diff1\n",
    "                elif diff == 1:\n",
    "                    diff_timesteps = 46-28\n",
    "                    start_timestep = 28-1\n",
    "                    diff_values = diff2\n",
    "                else:\n",
    "                    diff_timesteps = 69-51\n",
    "                    start_timestep = 51-1\n",
    "                    diff_values = diff3\n",
    "\n",
    "                regr_values = []\n",
    "\n",
    "                for i in range(diff_values.shape[2]):\n",
    "\n",
    "                    if diff_values[:, :, i] == 0:\n",
    "                        regr_value = torch.zeros(1, 1).unsqueeze(1)\n",
    "                    else:\n",
    "                        regr_value = torch.tensor(diff_values[:, :, i] / diff_timesteps).unsqueeze(1)\n",
    "\n",
    "                    regr_values.append(regr_value)\n",
    "\n",
    "                regr_values = torch.cat(regr_values, dim=-1)\n",
    "\n",
    "                for next_step in range(diff_timesteps):\n",
    "                    timestep = out[:, start_timestep+next_step, :].unsqueeze(1)\n",
    "                    out[:, start_timestep+next_step+1, :] = timestep + regr_values\n",
    "\n",
    "        # If northern hemisphere, place fractions at the middle months      \n",
    "        else:\n",
    "\n",
    "            out[:, 0:14, :] = test_Y[sample, 0, :].unsqueeze(0).unsqueeze(1).repeat_interleave(14, dim=1)\n",
    "            out[:, 32:37, :] = test_Y[sample, 1, :].unsqueeze(0).unsqueeze(1).repeat_interleave(5, dim=1)\n",
    "            out[:, 55:60, :] = test_Y[sample, 2, :].unsqueeze(0).unsqueeze(1).repeat_interleave(5, dim=1)\n",
    "            out[:, 78:, :] = test_Y[sample, 3, :].unsqueeze(0).unsqueeze(1).repeat_interleave(14, dim=1)\n",
    "\n",
    "            diff1 = (out[:, 32, :] - out[:, 13, :]).unsqueeze(1)\n",
    "            diff2 = (out[:, 55, :] - out[:, 36, :]).unsqueeze(1)\n",
    "            diff3 = (out[:, 78, :] - out[:, 59, :]).unsqueeze(1)\n",
    "\n",
    "            for diff in range(3):\n",
    "\n",
    "                if diff == 0:\n",
    "                    diff_timesteps = 32-14\n",
    "                    start_timestep = 14-1\n",
    "                    diff_values = diff1\n",
    "                elif diff == 1:\n",
    "                    diff_timesteps = 55-37\n",
    "                    start_timestep = 37-1\n",
    "                    diff_values = diff2\n",
    "                else:\n",
    "                    diff_timesteps = 78-60\n",
    "                    start_timestep = 60-1\n",
    "                    diff_values = diff3\n",
    "\n",
    "                regr_values = []\n",
    "\n",
    "                for i in range(diff_values.shape[2]):\n",
    "\n",
    "                    if diff_values[:, :, i] == 0:\n",
    "                        regr_value = torch.zeros(1, 1).unsqueeze(1)\n",
    "                    else:\n",
    "                        regr_value = torch.tensor(diff_values[:, :, i] / diff_timesteps).unsqueeze(1)\n",
    "\n",
    "                    regr_values.append(regr_value)\n",
    "\n",
    "                regr_values = torch.cat(regr_values, dim=-1)\n",
    "\n",
    "                for next_step in range(diff_timesteps):\n",
    "                    timestep = out[:, start_timestep+next_step, :].unsqueeze(1)\n",
    "                    out[:, start_timestep+next_step+1, :] = timestep + regr_values\n",
    "\n",
    "        # Append regressed sample to full regressed tensor list      \n",
    "        regressed_tensor.append(out)\n",
    "\n",
    "    # Concatenate into full shape [num samples, 92, 7]          \n",
    "    regressed_tensor = torch.cat(regressed_tensor, dim=0)\n",
    "\n",
    "    # Return tensor\n",
    "    return regressed_tensor\n",
    "\n",
    "# Perform function on data\n",
    "# Important, indice 1 in argument 1 needs to translate to unnormalised Y coord\n",
    "Y_regressed = RegressSamples(X_train, Y_train)\n",
    "\n",
    "print(\"\\n\", \"We now have regressed\", Y_train.shape, \"into\", Y_regressed.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample:\n",
      "tensor([[  0.,   0., 100.,   0.,   0.,   0.,   0.],\n",
      "        [  0.,   0., 100.,   0.,   0.,   0.,   0.],\n",
      "        [  0.,   0., 100.,   0.,   0.,   0.,   0.],\n",
      "        [  0.,   0.,  23.,  77.,   0.,   0.,   0.]]) \n",
      "\n",
      "Regressed sample:\n",
      "tensor([[  0.00,   0.00, 100.00,   0.00,   0.00,   0.00,   0.00],\n",
      "        [  0.00,   0.00, 100.00,   0.00,   0.00,   0.00,   0.00],\n",
      "        [  0.00,   0.00, 100.00,   0.00,   0.00,   0.00,   0.00],\n",
      "        [  0.00,   0.00, 100.00,   0.00,   0.00,   0.00,   0.00],\n",
      "        [  0.00,   0.00, 100.00,   0.00,   0.00,   0.00,   0.00],\n",
      "        [  0.00,   0.00, 100.00,   0.00,   0.00,   0.00,   0.00],\n",
      "        [  0.00,   0.00, 100.00,   0.00,   0.00,   0.00,   0.00],\n",
      "        [  0.00,   0.00, 100.00,   0.00,   0.00,   0.00,   0.00],\n",
      "        [  0.00,   0.00, 100.00,   0.00,   0.00,   0.00,   0.00],\n",
      "        [  0.00,   0.00, 100.00,   0.00,   0.00,   0.00,   0.00],\n",
      "        [  0.00,   0.00, 100.00,   0.00,   0.00,   0.00,   0.00],\n",
      "        [  0.00,   0.00, 100.00,   0.00,   0.00,   0.00,   0.00],\n",
      "        [  0.00,   0.00, 100.00,   0.00,   0.00,   0.00,   0.00],\n",
      "        [  0.00,   0.00, 100.00,   0.00,   0.00,   0.00,   0.00],\n",
      "        [  0.00,   0.00, 100.00,   0.00,   0.00,   0.00,   0.00],\n",
      "        [  0.00,   0.00, 100.00,   0.00,   0.00,   0.00,   0.00],\n",
      "        [  0.00,   0.00, 100.00,   0.00,   0.00,   0.00,   0.00],\n",
      "        [  0.00,   0.00, 100.00,   0.00,   0.00,   0.00,   0.00],\n",
      "        [  0.00,   0.00, 100.00,   0.00,   0.00,   0.00,   0.00],\n",
      "        [  0.00,   0.00, 100.00,   0.00,   0.00,   0.00,   0.00],\n",
      "        [  0.00,   0.00, 100.00,   0.00,   0.00,   0.00,   0.00],\n",
      "        [  0.00,   0.00, 100.00,   0.00,   0.00,   0.00,   0.00],\n",
      "        [  0.00,   0.00, 100.00,   0.00,   0.00,   0.00,   0.00],\n",
      "        [  0.00,   0.00, 100.00,   0.00,   0.00,   0.00,   0.00],\n",
      "        [  0.00,   0.00, 100.00,   0.00,   0.00,   0.00,   0.00],\n",
      "        [  0.00,   0.00, 100.00,   0.00,   0.00,   0.00,   0.00],\n",
      "        [  0.00,   0.00, 100.00,   0.00,   0.00,   0.00,   0.00],\n",
      "        [  0.00,   0.00, 100.00,   0.00,   0.00,   0.00,   0.00],\n",
      "        [  0.00,   0.00, 100.00,   0.00,   0.00,   0.00,   0.00],\n",
      "        [  0.00,   0.00, 100.00,   0.00,   0.00,   0.00,   0.00],\n",
      "        [  0.00,   0.00, 100.00,   0.00,   0.00,   0.00,   0.00],\n",
      "        [  0.00,   0.00, 100.00,   0.00,   0.00,   0.00,   0.00],\n",
      "        [  0.00,   0.00, 100.00,   0.00,   0.00,   0.00,   0.00],\n",
      "        [  0.00,   0.00, 100.00,   0.00,   0.00,   0.00,   0.00],\n",
      "        [  0.00,   0.00, 100.00,   0.00,   0.00,   0.00,   0.00],\n",
      "        [  0.00,   0.00, 100.00,   0.00,   0.00,   0.00,   0.00],\n",
      "        [  0.00,   0.00, 100.00,   0.00,   0.00,   0.00,   0.00],\n",
      "        [  0.00,   0.00, 100.00,   0.00,   0.00,   0.00,   0.00],\n",
      "        [  0.00,   0.00, 100.00,   0.00,   0.00,   0.00,   0.00],\n",
      "        [  0.00,   0.00, 100.00,   0.00,   0.00,   0.00,   0.00],\n",
      "        [  0.00,   0.00, 100.00,   0.00,   0.00,   0.00,   0.00],\n",
      "        [  0.00,   0.00, 100.00,   0.00,   0.00,   0.00,   0.00],\n",
      "        [  0.00,   0.00, 100.00,   0.00,   0.00,   0.00,   0.00],\n",
      "        [  0.00,   0.00, 100.00,   0.00,   0.00,   0.00,   0.00],\n",
      "        [  0.00,   0.00, 100.00,   0.00,   0.00,   0.00,   0.00],\n",
      "        [  0.00,   0.00, 100.00,   0.00,   0.00,   0.00,   0.00],\n",
      "        [  0.00,   0.00, 100.00,   0.00,   0.00,   0.00,   0.00],\n",
      "        [  0.00,   0.00, 100.00,   0.00,   0.00,   0.00,   0.00],\n",
      "        [  0.00,   0.00, 100.00,   0.00,   0.00,   0.00,   0.00],\n",
      "        [  0.00,   0.00, 100.00,   0.00,   0.00,   0.00,   0.00],\n",
      "        [  0.00,   0.00, 100.00,   0.00,   0.00,   0.00,   0.00],\n",
      "        [  0.00,   0.00,  95.72,   4.28,   0.00,   0.00,   0.00],\n",
      "        [  0.00,   0.00,  91.44,   8.56,   0.00,   0.00,   0.00],\n",
      "        [  0.00,   0.00,  87.17,  12.83,   0.00,   0.00,   0.00],\n",
      "        [  0.00,   0.00,  82.89,  17.11,   0.00,   0.00,   0.00],\n",
      "        [  0.00,   0.00,  78.61,  21.39,   0.00,   0.00,   0.00],\n",
      "        [  0.00,   0.00,  74.33,  25.67,   0.00,   0.00,   0.00],\n",
      "        [  0.00,   0.00,  70.06,  29.94,   0.00,   0.00,   0.00],\n",
      "        [  0.00,   0.00,  65.78,  34.22,   0.00,   0.00,   0.00],\n",
      "        [  0.00,   0.00,  61.50,  38.50,   0.00,   0.00,   0.00],\n",
      "        [  0.00,   0.00,  57.22,  42.78,   0.00,   0.00,   0.00],\n",
      "        [  0.00,   0.00,  52.94,  47.06,   0.00,   0.00,   0.00],\n",
      "        [  0.00,   0.00,  48.67,  51.33,   0.00,   0.00,   0.00],\n",
      "        [  0.00,   0.00,  44.39,  55.61,   0.00,   0.00,   0.00],\n",
      "        [  0.00,   0.00,  40.11,  59.89,   0.00,   0.00,   0.00],\n",
      "        [  0.00,   0.00,  35.83,  64.17,   0.00,   0.00,   0.00],\n",
      "        [  0.00,   0.00,  31.56,  68.44,   0.00,   0.00,   0.00],\n",
      "        [  0.00,   0.00,  27.28,  72.72,   0.00,   0.00,   0.00],\n",
      "        [  0.00,   0.00,  23.00,  77.00,   0.00,   0.00,   0.00],\n",
      "        [  0.00,   0.00,  23.00,  77.00,   0.00,   0.00,   0.00],\n",
      "        [  0.00,   0.00,  23.00,  77.00,   0.00,   0.00,   0.00],\n",
      "        [  0.00,   0.00,  23.00,  77.00,   0.00,   0.00,   0.00],\n",
      "        [  0.00,   0.00,  23.00,  77.00,   0.00,   0.00,   0.00],\n",
      "        [  0.00,   0.00,  23.00,  77.00,   0.00,   0.00,   0.00],\n",
      "        [  0.00,   0.00,  23.00,  77.00,   0.00,   0.00,   0.00],\n",
      "        [  0.00,   0.00,  23.00,  77.00,   0.00,   0.00,   0.00],\n",
      "        [  0.00,   0.00,  23.00,  77.00,   0.00,   0.00,   0.00],\n",
      "        [  0.00,   0.00,  23.00,  77.00,   0.00,   0.00,   0.00],\n",
      "        [  0.00,   0.00,  23.00,  77.00,   0.00,   0.00,   0.00],\n",
      "        [  0.00,   0.00,  23.00,  77.00,   0.00,   0.00,   0.00],\n",
      "        [  0.00,   0.00,  23.00,  77.00,   0.00,   0.00,   0.00],\n",
      "        [  0.00,   0.00,  23.00,  77.00,   0.00,   0.00,   0.00],\n",
      "        [  0.00,   0.00,  23.00,  77.00,   0.00,   0.00,   0.00],\n",
      "        [  0.00,   0.00,  23.00,  77.00,   0.00,   0.00,   0.00],\n",
      "        [  0.00,   0.00,  23.00,  77.00,   0.00,   0.00,   0.00],\n",
      "        [  0.00,   0.00,  23.00,  77.00,   0.00,   0.00,   0.00],\n",
      "        [  0.00,   0.00,  23.00,  77.00,   0.00,   0.00,   0.00],\n",
      "        [  0.00,   0.00,  23.00,  77.00,   0.00,   0.00,   0.00],\n",
      "        [  0.00,   0.00,  23.00,  77.00,   0.00,   0.00,   0.00],\n",
      "        [  0.00,   0.00,  23.00,  77.00,   0.00,   0.00,   0.00],\n",
      "        [  0.00,   0.00,  23.00,  77.00,   0.00,   0.00,   0.00],\n",
      "        [  0.00,   0.00,  23.00,  77.00,   0.00,   0.00,   0.00]])\n"
     ]
    }
   ],
   "source": [
    "# Check certain sample\n",
    "i = 236\n",
    "\n",
    "torch.set_printoptions(sci_mode=False, precision=2, linewidth=100)\n",
    "\n",
    "print(\"Original sample:\")\n",
    "print(Y_new[i, :, :].detach(), \"\\n\")\n",
    "print(\"Regressed sample:\")\n",
    "print(Y_regressed[i, :, :].detach())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep unnormalised Y coord (indice 1)\n",
    "X_train_Y_coord = X_train[:, :, 1].unsqueeze(2)\n",
    "X_new_Y_coord = X_new[:, :, 1].unsqueeze(2)\n",
    "X_vali_Y_coord = X_vali[:, :, 1].unsqueeze(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, random_split\n",
    "\n",
    "# Use X_train and Y_train for original training data\n",
    "# Use X_new and Y_new for upsampled training data\n",
    "\n",
    "# Calculate the mean and standard deviation of each feature in the training set\n",
    "X_mean = X_train.mean(dim=0)\n",
    "X_std = X_train.std(dim=0)\n",
    "Upsampled_X_mean = X_new.mean(dim=0)\n",
    "Upsampled_X_std = X_new.std(dim=0)\n",
    "\n",
    "# Standardize the training set\n",
    "X_train = (X_train - X_mean) / X_std\n",
    "X_new = (X_new - Upsampled_X_mean) / Upsampled_X_std\n",
    "\n",
    "# Standardize the vali set using the mean and standard deviation of the training set\n",
    "X_vali = (X_vali - Upsampled_X_mean) / Upsampled_X_std\n",
    "\n",
    "# Bind unnormalised Y coord with normalised data\n",
    "X_train_plusCoord = torch.cat([X_train_Y_coord, X_train], dim=-1)\n",
    "X_new_plusCoord = torch.cat([X_new_Y_coord, X_new], dim=-1)\n",
    "X_vali_plusCoord = torch.cat([X_vali_Y_coord, X_vali], dim=-1)\n",
    "\n",
    "# Create the TensorDataset for the training set\n",
    "train_dataset = TensorDataset(X_train_plusCoord, Y_train)\n",
    "upsampled_train_dataset = TensorDataset(X_new_plusCoord, Y_new)\n",
    "regressed_train_dataset = TensorDataset(X_train_plusCoord, Y_regressed)\n",
    "\n",
    "# Split\n",
    "train_size = int(0.8 * X_train_plusCoord.size(0)) \n",
    "test_size = X_train_plusCoord.size(0) - train_size\n",
    "\n",
    "# Training test data set\n",
    "train_dataset, test_dataset = random_split(regressed_train_dataset, [train_size, test_size])\n",
    "\n",
    "# Create the TensorDataset for the vali set\n",
    "vali_dataset = TensorDataset(X_vali_plusCoord, Y_vali)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define and apply LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer: Adam, LR: 0.001, hidden size: 256, epochs = 100, batch size = 64, no activation (SmoothL1 loss) (non-dense)\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "\n",
    "# Bidirectional LSTM\n",
    "class BiLSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=1, dropout=0.5):\n",
    "        super().__init__()\n",
    "        # LSTM \n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers=num_layers, bidirectional=True, batch_first=True)\n",
    "        \n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # Activation\n",
    "        self.activation = nn.Tanh()\n",
    "        \n",
    "        # Linear with Xavier Uniform\n",
    "        self.linear = nn.Linear(hidden_size*2, output_size) # x2 (bidirectional)\n",
    "#         init.xavier_uniform_(self.linear.weight)\n",
    "        \n",
    "        # Softmax\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        \n",
    "    def forward(self, x_input):\n",
    "        \n",
    "        # Don't use Y coordinate (first indice)\n",
    "        x = x_input[:, :, 1:]\n",
    "        \n",
    "        # Put input through LSTM layer\n",
    "        x, _ = self.lstm(x)\n",
    "        \n",
    "        # Put LSTM output through dropout layer (prevent overfitting)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Apply tanh activation function\n",
    "        x = self.activation(x)\n",
    "        \n",
    "        # Linear transform x to shape [batch size, sequence length = 92, output size = 7]\n",
    "        x = self.linear(x)\n",
    "        \n",
    "        # Make sure output distribution sums to 100\n",
    "        x = self.softmax(x) * 100\n",
    "        \n",
    "        # Create two outputs: dense and aggregated\n",
    "        # Aggregate based on Y > 0 (northern hemisphere) and Y < 0 (southern hemisphere)\n",
    "        agg_batch = []\n",
    "        for i in range(x_input.shape[0]):\n",
    "            if (x_input[i, :, 0] > 0).all(): # indice 1 is Y coordinate\n",
    "                mean1 = x[i, 9:13,:].unsqueeze(0).mean(dim=1).unsqueeze(1)\n",
    "                mean2 = x[i, 32:36,:].unsqueeze(0).mean(dim=1).unsqueeze(1)\n",
    "                mean3 = x[i, 55:59,:].unsqueeze(0).mean(dim=1).unsqueeze(1)\n",
    "                mean4 = x[i, 78:82,:].unsqueeze(0).mean(dim=1).unsqueeze(1)\n",
    "                agg_sample = torch.cat([mean1, mean2, mean3, mean4], dim=1) # [1, 4, 7]\n",
    "                agg_batch.append(agg_sample)      \n",
    "            else:\n",
    "                mean1 = x[i, 0:4,:].unsqueeze(0).mean(dim=1).unsqueeze(1)\n",
    "                mean2 = x[i, 23:27,:].unsqueeze(0).mean(dim=1).unsqueeze(1)\n",
    "                mean3 = x[i, 46:50,:].unsqueeze(0).mean(dim=1).unsqueeze(1)\n",
    "                mean4 = x[i, 69:73,:].unsqueeze(0).mean(dim=1).unsqueeze(1)\n",
    "                agg_sample = torch.cat([mean1, mean2, mean3, mean4], dim=1) # [1, 4, 7]\n",
    "                agg_batch.append(agg_sample)  \n",
    "        \n",
    "        x_agg = torch.cat(agg_batch, dim=0)\n",
    "        \n",
    "        return x, x_agg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom loss function\n",
    "def customloss(input, target):\n",
    "    dom_samples_idx = target[:, -1, -1] > 70\n",
    "    dom_input = input[~dom_samples_idx]\n",
    "    dom_target = target[~dom_samples_idx]\n",
    "\n",
    "    if dom_input.numel() > 0:\n",
    "        kldiv_loss = nn.KLDivLoss(reduction=\"batchmean\")(torch.log(dom_input), dom_target)  \n",
    "    else:\n",
    "        kldiv_loss = nn.KLDivLoss(reduction=\"batchmean\")(torch.log(input), target)\n",
    "    \n",
    "    l1 = nn.L1Loss()(input, target)\n",
    "    \n",
    "#     return (kldiv_loss/input.size(0))+l1\n",
    "    return nn.KLDivLoss(reduction=\"batchmean\")(torch.log(input), target)\n",
    "       \n",
    "# loss_fn = customloss\n",
    "loss_fn = nn.L1Loss()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train/run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of input and output features\n",
    "input_number = len(vars)\n",
    "output_number = len(targets)\n",
    "\n",
    "# Instantiate the model\n",
    "model = BiLSTMModel(input_size=input_number, hidden_size=256, output_size=output_number)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.001)\n",
    "\n",
    "# Create a DataLoader for the training set and validation sets (specify batch size)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=256, shuffle=True)\n",
    "vali_loader = torch.utils.data.DataLoader(vali_dataset, batch_size=256, shuffle=False)\n",
    "\n",
    "# Make lists to retain loss\n",
    "losses_train_epochs = []\n",
    "losses_test_epochs = []\n",
    "\n",
    "# But retain only the best prediction (to save memory)\n",
    "best_loss = float(\"inf\")\n",
    "mae = float(\"inf\")\n",
    "best_pred = []\n",
    "best_epoch = 0\n",
    "\n",
    "# Epochs\n",
    "num_epochs = 300 # The higher, the longer it takes but the better idea of the model's fitting ability\n",
    "    \n",
    "# Loop over the training data\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    # Progress\n",
    "    print(\"\\rAt epoch: {}/{}, Best loss: {} (obtained at epoch {})\".format(epoch, \n",
    "                                                                            num_epochs, \n",
    "                                                                            round(best_loss, 3),\n",
    "                                                                            best_epoch), end='\\r')\n",
    "\n",
    "    # Loss per epoch\n",
    "    epoch_trainloss = []\n",
    "    epoch_testloss = []\n",
    "\n",
    "    # Predictions per epoch\n",
    "    epoch_pred_agg = []\n",
    "    epoch_pred_dense = []\n",
    "    epoch_actual = []\n",
    "    epoch_pred_tensor = []\n",
    "    epoch_actual_tensor = []\n",
    "    \n",
    "    # Set the model to training mode  \n",
    "    model.train()\n",
    "\n",
    "    # Loop over the training set\n",
    "    for X, Y in train_loader:\n",
    "        \n",
    "        # Repeat Y 23 times, not if it is already regressed\n",
    "        if Y.shape[1] < 91:\n",
    "            Y = Y.repeat_interleave(repeats=23, dim=1)\n",
    "        else:\n",
    "            Y = Y\n",
    "\n",
    "        # Clear the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        Y_pred, _ = model(X)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = loss_fn(Y_pred, Y)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Append the loss to the lists\n",
    "        epoch_trainloss.append(loss.item())\n",
    "        \n",
    "        # Update the parameters\n",
    "        optimizer.step()\n",
    "       \n",
    "    with torch.no_grad():  \n",
    "        \n",
    "        # Set the model to evaluation mode\n",
    "        model.eval()\n",
    "        \n",
    "        # Loop over the test data set\n",
    "        for X, Y in test_loader:\n",
    "            \n",
    "            # Repeat Y 23 times, not if it is already regressed\n",
    "            if Y.shape[1] < 91:\n",
    "                Y = Y.repeat_interleave(repeats=23, dim=1)\n",
    "            else:\n",
    "                Y = Y\n",
    "\n",
    "            # Forward pass\n",
    "            Y_pred_dense, _ = model(X)\n",
    "\n",
    "            # Compute the loss     \n",
    "            loss = loss_fn(Y_pred_dense, Y)\n",
    "\n",
    "            # Append the loss to the list\n",
    "            epoch_testloss.append(loss.item())\n",
    "\n",
    "        # Make predictions\n",
    "        # Loop over the vali data set\n",
    "        for X, Y in vali_loader:\n",
    "\n",
    "            # Forward pass\n",
    "            Y_pred_dense, Y_pred_agg = model(X)\n",
    "\n",
    "            # Store predictions for batch\n",
    "            Y_pred_dense_list = [x.tolist() for x in Y_pred_dense]\n",
    "            Y_pred_agg_list = [x.tolist() for x in Y_pred_agg]\n",
    "            Y_list = [x.tolist() for x in Y]\n",
    "\n",
    "            # Add batch prediction to list \n",
    "            epoch_pred_dense.append(Y_pred_dense_list)\n",
    "            epoch_pred_agg.append(Y_pred_agg_list)\n",
    "            epoch_actual.append(Y_list)\n",
    "\n",
    "            # Retain tensors per batch\n",
    "            epoch_pred_tensor.append(Y_pred_agg)\n",
    "            epoch_actual_tensor.append(Y)\n",
    "    \n",
    "    # Add epoch losses to total loss list \n",
    "    losses_train_epochs.append(epoch_trainloss)\n",
    "    losses_test_epochs.append(epoch_testloss)\n",
    "\n",
    "    # Check if the current epoch achieved the lowest observed loss, if so, save epoch prediction\n",
    "    if (sum(epoch_testloss) / len(test_loader)) < best_loss:\n",
    "        best_loss = sum(epoch_testloss) / len(test_loader)\n",
    "        best_pred = epoch_pred_agg\n",
    "        best_pred_dense = epoch_pred_dense\n",
    "        best_actual = epoch_actual\n",
    "        best_epoch = epoch\n",
    "        \n",
    "        # In case of crash, save dicts\n",
    "#         torch.save(model.state_dict(), \"LSTM/Model Dicts/Dense_model_dict.pt\")\n",
    "#         torch.save(optimizer.state_dict(), \"LSTM/Model Dicts/Dense_optim_dict.pt\")\n",
    "\n",
    "print(\"\\n\", \"Done\")\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See losses\n",
    "Take prediction from epoch with lowest validation (vali) loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lowest loss: 9.78 is found at epoch: 121 \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Average loss per epoch\n",
    "ltrain_epochs = []\n",
    "for epoch_list in losses_train_epochs:\n",
    "  epoch_avg = sum(epoch_list) / len(train_loader)\n",
    "  ltrain_epochs.append(epoch_avg)\n",
    "\n",
    "ltest_epochs = []\n",
    "for epoch_list in losses_test_epochs:\n",
    "  epoch_avg = sum(epoch_list) / len(vali_loader)\n",
    "  ltest_epochs.append(epoch_avg)\n",
    "\n",
    "# Print epoch achieving minimum vali loss\n",
    "min_value = min(ltest_epochs)\n",
    "min_index = ltest_epochs.index(min_value)\n",
    "\n",
    "print(\"The lowest loss:\", round(min_value,2), \"is found at epoch:\", min_index, \"\\n\")\n",
    "\n",
    "# Plot the losses over time\n",
    "plt.plot(ltrain_epochs, label=\"Training loss\")\n",
    "plt.plot(ltest_epochs, label=\"Validation loss\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Average loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See (and check) predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from statistics import mean\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# # Make lists of predictions and actual fractions (reference)\n",
    "nested_pred = best_pred # results from the epoch with the minimum loss is taken\n",
    "nested_actual = best_actual\n",
    "\n",
    "unnested_pred = []\n",
    "for data in nested_pred:\n",
    "  for batch in data:\n",
    "    for timestep in batch:\n",
    "      for target in range(len(timestep)):\n",
    "        unnested_pred.append(timestep[target])\n",
    "\n",
    "unnested_actual = []\n",
    "for data in nested_actual:\n",
    "  for batch in data:\n",
    "    for timestep in batch:\n",
    "      for target in range(len(timestep)):\n",
    "        unnested_actual.append(timestep[target])\n",
    "\n",
    "# These lists contain output for entire predictions \n",
    "# Now retain lists for each class\n",
    "pred_class = {}\n",
    "true_class = {}\n",
    "\n",
    "# Also retain dense predictions\n",
    "pred_dense_class = {}\n",
    "nested_dense_pred = best_pred_dense\n",
    "\n",
    "unnested_dense_pred = []\n",
    "for data in nested_dense_pred:\n",
    "  for batch in data:\n",
    "    for timestep in batch:\n",
    "      for target in range(len(timestep)):\n",
    "        unnested_dense_pred.append(timestep[target])\n",
    "\n",
    "# Initialize lists for each class in predictions\n",
    "for i in range(len(targets)):\n",
    "  pred_class[f'{targets[i]}'] = unnested_pred[i::len(targets)]\n",
    "\n",
    "# And dense\n",
    "for i in range(len(targets)):\n",
    "  pred_dense_class[f'{targets[i]}'] = unnested_dense_pred[i::len(targets)]\n",
    "\n",
    "# Initialize lists for each class in reference data\n",
    "for i in range(len(targets)):\n",
    "  true_class[f'{targets[i]}'] = unnested_actual[i::len(targets)]\n",
    "\n",
    "RMSEavg = 0\n",
    "MAEavg = 0\n",
    "\n",
    "# Plot the lists as graphs\n",
    "\n",
    "# Loop through the data and plot the actual and predicted values\n",
    "for i in range(len(targets)):\n",
    "    # Get the data for the current class\n",
    "    true = true_class[f'{targets[i]}']\n",
    "    predicted = pred_class[f'{targets[i]}']\n",
    "\n",
    "    # Define the x-axis data as a range of values from 0 to the length of the data\n",
    "    x = range(len(true))\n",
    "\n",
    "    # Create a new figure\n",
    "    fig = plt.figure(i)\n",
    "\n",
    "    # Create a figure with certain size\n",
    "    fig = plt.figure(figsize=(20, 3))\n",
    "\n",
    "    # Create axes\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "    # Plot the actual and predicted values\n",
    "    ax.plot(x, true, label='Actual')\n",
    "    ax.plot(x, predicted, label='Predicted')\n",
    "\n",
    "    # Add a legend\n",
    "    ax.legend()\n",
    "\n",
    "    # Set the title using the class name\n",
    "    var_name = f'{targets[i]}'\n",
    "    ax.set_title(var_name)\n",
    "\n",
    "    # Show the figure\n",
    "    plt.show()\n",
    "\n",
    "    # Print RMSE / MAE\n",
    "    rmse = mean_squared_error(predicted, true) ** 0.5\n",
    "    RMSEavg = RMSEavg + rmse\n",
    "    print(f'RMSE for {var_name}: {round(rmse, 2)}')\n",
    "\n",
    "    difference = [abs(predicted - true) for predicted, true in zip(predicted, true)]\n",
    "    mae = mean(difference)\n",
    "    MAEavg = MAEavg + mae\n",
    "    print(f'MAE for {var_name}: {round(mae, 2)}')\n",
    "\n",
    "print(\"\\n\")\n",
    "RMSEavg = RMSEavg / len(targets)\n",
    "MAEavg = MAEavg / len(targets)\n",
    "\n",
    "print(f'Average RMSE is {round(RMSEavg, 2)} and average MAE is {round(MAEavg, 2)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create prediction data frame and write to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# # Make lists of predictions and actual fractions (reference)\n",
    "nested_pred = best_pred # results from the epoch with the minimum loss is taken\n",
    "nested_actual = best_actual\n",
    "\n",
    "unnested_pred = []\n",
    "for data in nested_pred:\n",
    "  for batch in data:\n",
    "    for timestep in batch:\n",
    "      for target in range(len(timestep)):\n",
    "        unnested_pred.append(timestep[target])\n",
    "\n",
    "unnested_actual = []\n",
    "for data in nested_actual:\n",
    "  for batch in data:\n",
    "    for timestep in batch:\n",
    "      for target in range(len(timestep)):\n",
    "        unnested_actual.append(timestep[target])\n",
    "\n",
    "# These lists contain output for entire predictions \n",
    "# Now retain lists for each class\n",
    "pred_class = {}\n",
    "true_class = {}\n",
    "\n",
    "# Also retain dense predictions\n",
    "pred_dense_class = {}\n",
    "nested_dense_pred = best_pred_dense\n",
    "\n",
    "unnested_dense_pred = []\n",
    "for data in nested_dense_pred:\n",
    "  for batch in data:\n",
    "    for timestep in batch:\n",
    "      for target in range(len(timestep)):\n",
    "        unnested_dense_pred.append(timestep[target])\n",
    "\n",
    "# Initialize lists for each class in predictions\n",
    "for i in range(len(targets)):\n",
    "  pred_class[f'{targets[i]}'] = unnested_pred[i::len(targets)]\n",
    "\n",
    "# And dense\n",
    "for i in range(len(targets)):\n",
    "  pred_dense_class[f'{targets[i]}'] = unnested_dense_pred[i::len(targets)]\n",
    "\n",
    "# Initialize lists for each class in reference data\n",
    "for i in range(len(targets)):\n",
    "  true_class[f'{targets[i]}'] = unnested_actual[i::len(targets)]\n",
    "\n",
    "\n",
    "# Add IDs (vali data was not shuffled so can add like this --- checked with excel!)\n",
    "# First need to increase rows (as was done with the other data)\n",
    "ID_tensor = ID_vali.repeat_interleave(repeats=23, dim=1)\n",
    "\n",
    "# This was the order of columns we made the tensor\n",
    "column_names = ['sample_id', 'location_id', 'validation_id', 'reference_year',\n",
    "                'x', 'y']\n",
    "\n",
    "# make the ID tensor to a shape with correct amount rows and columns\n",
    "ID_array = ID_vali.numpy().reshape(-1,len(column_names))\n",
    "ID_array_dense = ID_tensor.numpy().reshape(-1,len(column_names))\n",
    "\n",
    "# Create dfs (also create vali df)\n",
    "pred_df = pd.DataFrame(ID_array, columns=column_names)\n",
    "dense_pred_df = pd.DataFrame(ID_array_dense, columns=column_names)\n",
    "# pred_df = pd.DataFrame(ID_vali, columns=column_names)\n",
    "# dense_pred_df = pd.DataFrame(ID_array, columns=column_names)\n",
    "\n",
    "# Adds predictions to df \n",
    "for i in range(len(targets)):\n",
    "    data = pred_class[f'{targets[i]}']\n",
    "    data_dense = pred_dense_class[f'{targets[i]}']\n",
    "\n",
    "    pred_df[targets[i]] = data \n",
    "    dense_pred_df[targets[i]] = data_dense \n",
    "\n",
    "# Show df\n",
    "# pred_df.head(12)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "pred_df.to_csv('Output/LSTM/LSTM_dense_to_agg.csv')\n",
    "dense_pred_df.to_csv('Output/LSTM/LSTM_dense.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
